# :star2: 最具影響力的 RAG 論文

### (2023年3月到2024年6月)

檢索增強生成（RAG）的概念是在2021年通過[開創性論文](https://arxiv.org/abs/2005.11401)引入的。自那時以來，RAG研究有了顯著增長，特別是在過去一年中，由於眾多LLM的出現。RAG已成為LLM最廣泛使用的應用之一。下表提供了2023年3月至2024年5月間發表的頂級論文摘要，涵蓋了與RAG研究相關的各種主題。這些主題包括:

1. **RAG 調查**: 現有 RAG 方法的綜合概述。
2. **RAG 增強（進階技術）**: 提出改進 RAG 管線效率和效果的建議。
3. **檢索改進**: 專注於提升 RAG 檢索元件的技術。
4. **比較論文**: 比較 RAG 與其他方法或方法的研究。
5. **特定領域 RAG**: 為特定領域或應用調整 RAG 技術。
6. **RAG 評估**: 評估 RAG 模型的性能和效果。
7. **RAG 嵌入**: 開發優化 RAG 或 RAG 檢索的更好嵌入技術的方法。
8. **RAG 的輸入處理**: 用於預處理輸入數據以優化 RAG 模型性能和效果的技術。

這個表格將會定期更新，請持續關注更多更新！

| 標題 | 描述 | 標籤 | 日期 |
|-------|-------------|------|------|
|[Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework](https://arxiv.org/abs/2406.14783)|本文探討評估檢索增強生成（RAG）問答系統的挑戰，聚焦於特定領域知識幻覺以及缺乏適當的基準。為了解決這些問題，作者提出了一個綜合評估框架，使用大型語言模型（LLM）生成合成查詢，評估檢索的文檔和答案，並通過名為RAGElo的自動化Elo競爭對RAG變體進行排名。| RAG 評估 | 2024年6月 |
|[LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](https://arxiv.org/abs/2406.15319)|傳統的RAG框架中，短檢索單元（如DPR）使用100字的維基百科段落，效率低下。為了解決這個問題，LongRAG引入了「長檢索器」和「長閱讀器」框架，將維基百科處理成4000個字的單元，從而顯著減少單元數量，同時提高檢索得分。在NQ數據集上的答案召回率@1達到71%，在HotpotQA（完整維基）上的答案召回率@2達到72%。LongRAG將這些檢索到的單元提供給長上下文LLM進行零樣本答案提取，展示了在NQ和HotpotQA上的最新性能，分別達到62.7%和64.3%的精確匹配分數，無需訓練。| RAG 增強 | 2024年6月 |
|[PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers](https://arxiv.org/abs/2406.12430)|本文介紹了適用於遊戲場景（如《歐洲風雲IV》和《維多利亞3》）的Decision QA基準，旨在解決決策任務。它還提出了PlanRAG，一種新型RAG技術，該技術讓語言模型生成決策計劃並使用檢索器進行資料查詢。在定位場景中，PlanRAG的性能比現有的迭代RAG方法高出15.8%，在構建場景中高出7.4%。| RAG 增強 | 2024年6月 |
|[From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries](https://arxiv.org/abs/2406.12824)|本文機械地研究了RAG，揭示了語言模型主要依賴上下文信息而非參數記憶來回答問題。他們使用因果中介分析來展示參數記憶的最小利用，並通過注意力貢獻和淘汰來分析最後一個標記的殘差流是從信息豐富的上下文標記而非直接來自問題的主題標記中得到增強的。| RAG 增強 | 2024年6月 |
|[Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models]()|本文介紹了Buffer of Thoughts（BoT），一種新穎的方法，通過使用元緩衝區儲存和適應信息豐富的思維模板來增強LLM的推理能力。在10個推理密集的任務中，BoT顯示出顯著的性能提升，展示了卓越的泛化能力和魯棒性，同時比多查詢提示方法具有更低的計算成本。| RAG 增強 | 2024年6月 |
|[SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation](https://arxiv.org/abs/2406.19215)|本文介紹了自覺知識檢索（SeaKR），這是一種新穎的自適應RAG模型，利用LLM的自覺不確定性來增強知識檢索和整合。SeaKR在LLM表現出高度不確定性時啟動檢索，根據片段的潛在減少不確定性的能力重新排名檢索到的片段。對於需要多次檢索的任務，SeaKR使用自覺不確定性來選擇最佳推理策略。實驗結果顯示，SeaKR在各種問答數據集上優於現有的自適應RAG方法。| RAG 增強 | 2024年6月 |
|[RE-AdaptIR: Improving Information Retrieval through Reverse Engineered Adaptation](https://arxiv.org/abs/2406.14764)|本文探討了通過反向工程適應（RE-AdaptIR）來增強大型語言模型（LLM）在信息檢索（IR）中的性能，無需大量標註示例。通過應用RE-AdaptIR，研究顯示了在訓練領域和零樣本場景中遇到新查詢時性能的顯著提升。這些發現為該領域的從業者提供了可行的見解。|檢索改進 |2024年6月|
|[CRAG -- Comprehensive RAG Benchmark](https://arxiv.org/abs/2406.04744)|綜合RAG基準（CRAG）通過提供一組多樣且動態的4,409個問答對和模擬網絡及知識圖譜搜尋的模擬API，解決了現有RAG數據集的限制。CRAG評估了LLM在各個領域和問題類別上的問答能力，揭示了即使是最新的RAG解決方案在準確性上也存在困難，特別是對於動態性較高、知名度較低或複雜性較高的問題。該基準已經促進了顯著的參與，為RAG和一般問答解決方案的未來研究和改進鋪平了道路。| RAG 評估 | 2024年6月 |
|[A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems](https://arxiv.org/abs/2406.14972)|與常見的優化指令遵循的「指導」LLM的做法相反，本研究發現基礎模型在RAG任務中的表現平均比指導模型高出20%。這挑戰了指導LLM在RAG應用中優越性的普遍假設，並強調了進一步研究和討論的必要性。| RAG 增強 | 2024年6月 |
|[Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts](https://arxiv.org/pdf/2405.19893)|該研究強調了當前大型語言模型在知識密集型任務中的局限性，如不及時性、高成本的知識更新和幻覺。它介紹了METRAG，一種多層思維增強的檢索增強生成框架，超越了傳統的相似性導向方法，通過結合相似性和效用導向的思維，並使用LLM作為任務自適應摘要器。廣泛的實驗表明，METRAG顯著提升了檢索增強生成在知識密集型任務中的性能。| RAG 增強 | 2024年5月 |
|[HippoRAG Neurobiologically Inspired Long-Term Memory for Large Language Models](https://arxiv.org/abs/2405.14831)|該研究引入了HippoRAG，一種受海馬索引理論啟發的檢索框架，以增強大型語言模型中的知識整合。通過結合LLM、知識圖譜和個性化PageRank算法，HippoRAG模仿人類記憶過程。實驗表明，它在多跳問答中顯著優於現有方法，提供了更好的性能、成本效益和速度。| RAG 增強 | 2024年5月 |
|[Don't Forget to Connect! Improving RAG with Graph-based Reranking](https://arxiv.org/abs/2405.18414)|該研究探討了在文件具有部分信息或與上下文的關聯性較低的情況下，檢索增強生成面臨的挑戰。引入了基於圖神經網絡（GNN）的重新排序器G-RAG，該方法結合了文件連接和語義信息，以增強RAG。G-RAG的計算負擔較小，但顯著優於最新的方法，特別是作為重新排序器明顯優於PaLM 2，突顯了有效重新排序在RAG中的重要性。|檢索改進 | 2024年5月 |
|[GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning](https://arxiv.org/abs/2405.20139)|本文介紹了GNN-RAG，這是一種結合LLM和圖神經網絡（GNN）進行知識圖譜問答（KGQA）的方法。GNN-RAG使用GNN從密集的知識圖譜子圖中檢索答案候選，並讓LLM對提取的路徑進行推理。這種方法顯著提升了KGQA基準的性能，尤其是在多跳和多實體問題上，超越了包括GPT-4在內的最新模型。 | 領域特定RAG | 2024年5月 |
|[Observations on Building RAG Systems for Technical Documents](https://arxiv.org/pdf/2404.00657) |針對技術文檔的檢索增強生成（RAG）創建了挑戰，因為嵌入經常無法捕捉領域信息。本文回顧了影響RAG的重要因素，並進行了實驗以突顯構建技術文檔RAG系統的最佳實踐和潛在挑戰。 | RAG 調查| 2024年5月 |
| [RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing](https://arxiv.org/pdf/2404.19543) |該研究調查了LLM如何應對NLP挑戰，通過整合外部信息來提升性能。它探討了檢索增強語言模型（RALM），如RAG和RAU，詳細介紹了它們的演變、分類及其在各種NLP任務中的應用。討論了關鍵組件和評估方法，強調了其優勢、限制和未來研究方向，以提升檢索質量和效率。總體而言，這提供了對RALM在推進NLP方面潛力的結構化見解。| RAG 調查 | 2024年4月 |
| [When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively](https://arxiv.org/pdf/2404.19705) |該研究說明了LLM如何有效地與信息檢索（IR）系統整合，特別是在回答問題需要額外上下文時。建議流行問題通常由LLM的參數記憶回答，而不太流行的問題則受益於IR的使用。一種定制的訓練方法引入了一個特定的標記⟨RET⟩，用於LLM缺乏答案的問題，從而在PopQA數據集上展示了由自適應檢索LLM（ADAPT-LLM）實現的改進。評估顯示，ADAPT-LLM在需要IR的問題上使用⟨RET⟩，同時保持依賴參數記憶的高準確性。 | RAG 增強 | 2024年4月 |
| [A Survey on Retrieval-Augmented Text Generation for Large Language Models](https://arxiv.org/pdf/2404.10981) |本文介紹了檢索增強生成（RAG），通過結合檢索方法與深度學習，克服大型語言模型的靜態限制，整合實時外部信息。著重於文本生成，RAG減輕了LLM生成不準確回應的趨勢，通過現實世界數據提高可靠性。本文將RAG劃分為預檢索、檢索、後檢索和生成階段，概述了其演變並評估其性能，旨在整合研究、闡明其技術，並擴大LLM的適用性。 | RAG 調查 | 2024年4月 |
| [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://arxiv.org/abs/2403.06840) | RA-ISF提出了通過檢索增強的迭代自反饋來提高大型語言模型的問題解決能力，通過將任務分解成三個子模塊並迭代處理。實驗表明，它在現有基準（如GPT3.5和Llama2）上顯著提升了事實推理能力並減少了幻覺。 | RAG 增強 | 2024年3月 |
| [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) | 本文介紹了RAFT（檢索增強精調），一種旨在提高預訓練大型語言模型在特定領域背景下回答問題能力的訓練方法。RAFT重點適應模型，以忽略在問答過程中檢索到的不相關文檔。通過選擇性引用檢索到的文檔中的相關信息，RAFT改進了模型的推理能力和在各種數據集（如PubMed、HotpotQA和Gorilla）上的性能。| RAG 增強 | 2024年3月 |
| [Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge](https://arxiv.org/pdf/2403.01432.pdf) | 本文探討了檢索增強生成（RAG）和精調（FT）方法在提升大型語言模型在低頻實體問答任務中的性能方面的有效性。雖然FT在不同知名度的實體上顯示了顯著的改進，但RAG在其他方法中表現優異。此外，檢索和數據增強技術的進步增強了RAG和FT方法在處理低頻實體方面的成功。 | 比較研究 | 2024年3月 |
| [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) | 本文介紹了RETRO，一種通過檢索大量文檔來增強自回歸語言模型的方法。儘管使用的參數比現有模型（如GPT-3和Jurassic-1）少得多，但RETRO在問答等任務上的性能與之相當。通過結合冷凍Bert檢索器、可微編碼器和塊狀交叉注意機制，RETRO在預測期間利用了數量級更多的數據。這種方法為通過顯式記憶以前所未有的規模改進語言模型提供了新的可能性。 | RAG 增強LLM | 2024年3月 |
| [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](https://arxiv.org/abs/2403.05313) | RAT方法通過迭代修訂一系列檢索增強的思維，提升了大型語言模型在長期任務中的推理和生成能力。通過將檢索增強的思維納入模型（如GPT-3.5、GPT-4和CodeLLaMA-7b），RAT在代碼生成、數學推理、創意寫作和具體任務規劃等任務上顯著提升了性能，平均評分提升13.63%、16.96%、19.2%和42.78%。 | RAG 增強 | 2024年3月 |
| [Instruction-tuned Language Models are Better Knowledge Learners](https://arxiv.org/abs/2402.12847) | 本文介紹了指令調優語言模型是更好的知識學習者，提出了預指令調優（PIT），這是一種在文件訓練前對問題進行指令調優的方法，與標準方法相反。PIT顯著增強了LLM從新文件中吸收知識的能力，表現優於標準指令調優17.8%，在廣泛的實驗和消融研究中得到了證明。 | 指令調優 | 2024年2月 |
| [Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2402.10612) | 幻覺是大型語言模型面臨的一個重大挑戰，通常是由於內部知識的有限性造成的。雖然整合外部信息可以緩解這一問題，但也可能引入不相關的細節，導致外部幻覺。為應對這一問題，作者介紹了Rowen，該方法在檢測到跨語言的不一致時選擇性地增強LLM，這表明存在幻覺。這種語義感知過程平衡了內部推理與外部證據，有效地減少了幻覺。實證分析顯示，Rowen在檢測和減少LLM輸出中的幻覺內容方面優於現有方法。 | RAG 增強 | 2024年2月 |
| [G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering](https://arxiv.org/abs/2402.07630) | 本文介紹了GraphQA，一種通過對話界面交互查詢文本圖譜的框架，適用於各種現實應用。提出的G-Retriever結合了圖神經網絡、大型語言模型和檢索增強生成，以有效地導航大型文本圖譜。通過軟提示和優化技術，G-Retriever在性能和可擴展性方面顯示出優越性，並減少了幻覺問題。跨多個領域的實證評估證明了其有效性，展示了其在實際應用中的潛力。 | 檢索改進 | 2024年2月 |
| [Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks](https://arxiv.org/abs/2402.13482) | 檢索增強數據增強（RADA）是一種旨在改進低資源環境中模型性能的方法，適用於訓練數據有限的情況。RADA通過引入其他數據集中的示例來解決次優和多樣性較差的合成數據生成挑戰。它根據與給定種子數據的相似性檢索相關實例，並提示大型語言模型生成帶有原始和檢索樣本上下文信息的新樣本。實驗結果顯示，RADA在訓練和測試時的數據增強場景中，比現有的LLM驅動的數據增強方法更有效。 | 領域特定RAG | 2024年2月 |
| [RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval](https://arxiv.org/abs/2401.18059) | RAPTOR提出了一種新的檢索增強語言建模方法，通過引入一種從大文檔構建層次摘要樹的方法，實現更細緻和全面的檢索信息。與傳統方法直接從文本中提取短摘錄不同，RAPTOR的遞歸過程在多個抽象層次上嵌入、聚類和總結文本塊。這種結構化檢索使得對整個文檔的信息進行更深刻的理解和整合，在需要多步推理的複雜任務上顯著提升性能。基於多個基準的顯著改進，包括在QuALITY基準上提高20%的絕對準確率，顯示了RAPTOR在改進模型知識存取和應用方面的潛力，設立了問答等任務的新標準。 | RAG 增強 | 2024年1月 |
| [RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture](https://arxiv.org/abs/2401.08406) | 本文探討了開發人員將專有和特定領域數據整合到大型語言模型中的兩種方法：檢索增強生成和精調。詳細介紹了將這些方法應用於LLM（如Llama2-13B、GPT-3.5和GPT-4）的管道，重點在於提取信息、生成問題和答案、精調以及評估。本文展示了精調模型在利用跨地理信息方面的能力顯著提升，並強調了LLM在各種工業領域中的更廣泛應用和好處。 | 比較研究 | 2024年1月 |
| [Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884) | CRAG提出了一種新策略，在檢索增強生成過程中提高大型語言模型的魯棒性和準確性。為應對依賴檢索文檔相關性潛在問題，CRAG使用檢索評估器評估文檔質量和相關性，根據置信度得分啟用自適應檢索策略。為克服靜態數據庫的限制，CRAG整合了大規模網絡搜索，提供更豐富的文檔池。獨特的分解-再構成算法確保模型專注於相關信息，捨棄不相關內容，從而提高生成質量。CRAG作為一種多功能、即插即用的解決方案，顯著提升了基於RAG的模型在多種生成任務中的性能，通過四個不同數據集的實驗顯示出顯著改進。 | RAG 增強 | 2024年1月 |
| [UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems](https://arxiv.org/abs/2401.13256) | 本文介紹了UniMS-RAG，一種新框架，旨在通過整合多個知識源來解決對話系統中的個性化挑戰。該框架將任務分解為知識源選擇、知識檢索和回應生成三個子任務，並在訓練過程中將它們統一為一個序列到序列的範式。這允許模型使用特殊標記動態檢索和評估相關證據，促進與多樣化知識源的交互。此外，提出了一種自我改進機制，基於一致性和相關性分數迭代改進生成的回應。| 領域特定RAG | 2024年1月 |
| [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997) | 本調查深入探討了檢索增強生成作為解決大型語言模型面臨的挑戰的解決方案，包括幻覺和過時知識。RAG集成外部數據庫以提高準確性和可信度，特別是針對知識密集型任務，並實現連續的知識更新。本文回顧了RAG範式的演變，涵蓋了Naive RAG、Advanced RAG和Modular RAG，並檢視了檢索、生成和增強技術。討論了最新技術，並引入了一個更新的評估框架和基準，總結了當前的挑戰和未來研究方向。 | RAG 調查 | 2023年12月 |
| [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](https://arxiv.org/abs/2311.09210) | Chain-of-Noting（CoN）介紹了一種創新方法，通過處理不相關或噪音信息的問題，提高檢索增強語言模型（RALM）的魯棒性和可靠性，並增強模型識別缺乏充分知識回答問題的能力。CoN的策略包括在檢索到的文檔上創建連續的閱讀筆記，促進對其相關性的更詳細評估，並將這一評估整合到答案生成過程中。這種方法不僅有助於過濾掉無益信息，還使RALM更有信心地識別並承認某些問題超出其當前知識或數據範圍。利用ChatGPT進行訓練數據創建，並將CoN實施在LLaMa-2 7B模型上，該方法在開放域問答任務中顯示出顯著的性能提升。結果包括在噪音文檔檢索中顯著提高的精確匹配（EM）分數，並增強了對超出模型預訓練知識範圍問題的拒絕率，突顯了CoN在使RALM更可靠和值得信賴方面的潛力。 | RAG 增強LLM | 2023年11月 |
| [From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL](https://arxiv.org/abs/2311.06595) | 本文介紹了CREA-ICL，一種旨在通過跨語言檢索增強上下文學習（ICL）來提高多語言預訓練語言模型（MPLM）在低資源語言中零樣本學習能力的創新方法。通過從高資源語言中檢索語義相似的提示，這種方法旨在增強模型在各種任務中的表現。結果表明，在分類任務中一致改進；然而，該方法在應用於生成任務時遇到障礙。這些結果提供了有價值的見解，揭示了使用檢索增強上下文學習時分類和生成領域之間有效性差異的微妙挑戰和潛在策略，突顯了推進MPLM在多語言環境中應用的研究方向。 | 領域特定RAG | 2023年11月 |
| [REST: Retrieval-Based Speculative Decoding](https://arxiv.org/abs/2311.08252) | 本文介紹了REST，一種稱為檢索增強推測解碼的新算法，旨在加速語言模型的生成。與先前方法不同，REST利用檢索來生成基於文本生成過程中常見短語和模式的草稿標記。它無需額外訓練即可無縫集成到現有語言模型中，在單批次設置下，與7B和13B語言模型相比，在代碼或文本生成任務上實現了1.62倍至2.36倍的顯著加速。 | RAG 增強 | 2023年11月 |
| [Learning to Filter Context for Retrieval-Augmented Generation](https://arxiv.org/abs/2311.08377) | 本文介紹了FILCO方法，旨在提高檢索增強系統中提供給生成模型的上下文質量。通過識別有用的上下文並訓練上下文過濾模型，FILCO旨在減少生成過程中不相關段落引起的問題。在各種知識密集型任務中的實驗結果表明，FILCO在提高輸出質量方面超過了現有方法，在問答、事實驗證和對話生成等任務中顯示出優異性能。無論檢索上下文是否完美符合所需輸出，該方法都顯示出其有效性。 | RAG 增強 | 2023年11月 |
| [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511) | Self-RAG引入了一種新方法，通過結合檢索和自我反思來提高大型語言模型的質量和準確性。與傳統的檢索增強生成模型可能無差別地檢索和使用外部段落不同，Self-RAG採用了一種更動態的方法。它使LLM能夠自適應地決定何時檢索信息，並通過使用特殊的「反思標記」來批判性地評估檢索內容和自身生成的回應。這種創新機制允許模型根據具體任務調整行為，在推理過程中提供更高的控制度。在開放域問答、推理和事實驗證等多種任務上的測試顯示，Self-RAG模型（具有7B和13B參數）在性能上超過了傳統LLM和其他檢索增強模型，在生成事實和準確引用的長篇內容方面顯示出顯著改進。 | RAG 增強 | 2023年10月 |
| [Benchmarking Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2309.01431) | 本文探討了檢索增強生成如何影響大型語言模型在一系列核心能力上的性能，這些能力對RAG應用至關重要。通過建立檢索增強生成基準（RGB），這是一個專為RAG評估設計的新語料庫，覆蓋英語和中文，研究細緻評估了LLM在噪音魯棒性、負拒絕、信息整合和反事實魯棒性四個核心能力上的表現。對六個代表性LLM的分析揭示了它們的相對優勢和劣勢，顯示這些模型在噪音抵抗力上表現出色，但在拒絕不相關信息、整合多源信息和反駁錯誤信息方面存在顯著不足。這些發現強調了進一步改進LLM以充分利用RAG潛力的必要性，突顯了提高LLM事實準確性和決策過程的複雜性和挑戰。 | RAG 評估 | 2023年10月 |
| [Knowledge-Augmented Language Model Verification](https://arxiv.org/abs/2310.12836) | 本文介紹了一種新方法，旨在通過在知識增強過程中引入驗證步驟來提高語言模型回應的事實準確性。認識到語言模型經常因內部知識的局限性而產生事實錯誤的答案，這種方法通過識別和糾正檢索相關外部知識和生成文本中的錯誤來增強文本生成。一個經過指令微調訓練的小型語言模型專門用來檢測檢索和生成中的不準確性。識別出的錯誤可以通過更新檢索知識或修改生成文本來糾正。此外，通過引導不同指令的輸出組合並使用單一驗證器，提高了驗證的可靠性。在多個問答基準上的測試顯示，該方法顯著提高了回應的事實準確性，證明了驗證器在識別和解決知識檢索和文本生成錯誤方面的有效性。 | RAG 增強 | 2023年10月 |
| [Optimizing Retrieval-augmented Reader Models via Token Elimination](https://arxiv.org/abs/2310.13682) | 本研究介紹了一種方法，旨在提高Fusion-in-Decoder（FiD），一種在開放域任務（如問答和事實檢查）中廣泛使用的檢索增強語言模型的效率。通過分析每個檢索到的段落對模型性能的重要性，研究人員提出了一種方法，選擇性地在標記層面上消除非關鍵信息。這種標記消除策略顯著減少了解碼時間——高達62.2%——對模型的效果影響最小，僅降低2%的性能。令人驚訝的是，在某些情況下，這種方法不僅保持了模型的性能，還有所提高。這種方法為優化檢索增強讀取模型在計算效率和準確性之間的平衡提供了有前景的方向。 | RAG 增強LLM | 2023年10月 |
| [Self-Knowledge Guided Retrieval Augmentation for Large Language Models](https://arxiv.org/abs/2310.05002) | SKR（自知識引導檢索）是一種新方法，旨在通過智能整合外部知識來提升大型語言模型的性能。認識到LLM在知識完整性和可更新性方面的局限性，SKR重點提高LLM區分自己知道和不知道什麼的能力，使其能夠選擇性地尋求外部信息。這種方法旨在減少檢索基於方法有時會減損模型原始回應的問題。通過使LLM參考以前遇到的問題，並明智地利用外部資源來應對新查詢，SKR顯示出在各種數據集上超越現有方法的性能，利用InstructGPT或ChatGPT等模型提高了問答能力。 | 檢索改進 | 2023年10月 |
| [Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2310.14696) | 「澄清樹」（ToC）框架通過創建一個結構化的潛在解釋樹，解決開放域問答中含糊問題的挑戰，允許生成全面的長篇答案。該方法利用少量提示和外部知識來遞歸澄清問題並收集相關信息。在多個指標上，ToC不僅超越了其他少樣本方法，還在Disambig-F1和Disambig-ROUGE分數上超越了全監督方法，為理解和有效回答模糊問題提供了一種穩健解決方案。 | RAG 增強LLM | 2023年10月 |
| [Retrieval-Generation Synergy Augmented Large Language Models](https://arxiv.org/abs/2310.05149) | 本文介紹了一種新的迭代框架，結合檢索和生成過程來提升大型語言模型在知識密集型任務中的性能。這種協作方法允許模型訪問內部知識（內參數知識）和外部知識（來自外部來源），並通過檢索和生成階段之間的交互迭代細化其理解和輸出。這種協同作用特別有利於需要多步推理的複雜任務。在單跳和多跳問答數據集上的測試顯示，該方法顯著提高了LLM的推理能力，超越了現有方法。 | RAG 增強 | 2023年10月 |
| [RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation](https://arxiv.org/abs/2310.04408) | RECOMP引入了一種方法，通過在將檢索到的文檔集成到模型上下文之前對其進行壓縮，來優化檢索增強語言模型的效率。這種方法旨在使推理過程的資源需求降低，幫助LLM更有效地識別檢索文檔中的相關信息。RECOMP使用兩種類型的壓縮器：提取性壓縮器，識別並使用文檔中的關鍵句子；和抽象性壓縮器，通過結合來自多個來源的信息創建摘要。這些壓縮器旨在提高LLM的任務性能，同時生成簡短摘要，即使在檢索到的文檔無益時也能省略增強。 | RAG 增強 | 2023年10月 |
| [Retrieval meets Long Context Large Language Models](https://arxiv.org/abs/2310.03025) | 本文深入探討了檢索增強和擴展上下文窗口在大型語言模型中的相對優勢，並探討了它們的結合是否能在各種下游任務中產生更好的效果。使用兩個先進的LLM進行分析，結果顯示，具有較小上下文窗口（4000個標記）的模型在補充檢索增強後，可以匹配經過長上下文任務微調的大上下文窗口（16000個標記）模型的性能，但計算需求顯著降低。此外，將檢索整合到LLM中可以提高所有上下文窗口大小的性能。最突出的模型是一個具有32K上下文窗口的檢索增強Llama2-70B，在各種任務（包括問答和摘要）上顯著超越了領先的模型，如GPT-3.5-turbo-16k和Davinci003，並且生成速度更快。這項研究突顯了檢索增強在提高LLM效率和準確性方面的有效性，為未來的模型開發策略提供了有價值的指導。 | 比較研究 | 2023年10月 |
| [Making Retrieval-Augmented Language Models Robust to Irrelevant Context](https://arxiv.org/abs/2310.01558) | 本文探討了在多跳推理任務中確保檢索增強語言模型（RALM）在面對不相關信息時保持有效性和準確性的挑戰。通過對五個開放域問答基準的廣泛分析，作者識別了檢索增強實際上阻礙模型性能的情況。為了解決這一問題，他們引入了兩種策略：首先，使用自然語言推理模型過濾掉不支持問題答案的段落，以確保模型不會被不相關數據誤導。雖然這種方法在減少不準確性方面有效，但也有排除有用信息的風險。為了改進這一方法，作者開發了一種技術，通過在訓練過程中結合相關和不相關上下文，增強模型辨別和適當使用檢索段落的能力。令人驚訝的是，他們展示了一個只有1000個示例的數據集就能顯著提高模型在不相關信息面前的韌性，而不影響其對相關示例的性能。 | RAG 增強LLM | 2023年10月 |
| [RA-DIT: Retrieval-Augmented Dual Instruction Tuning](https://arxiv.org/abs/2310.01352) | RA-DIT提出了一種新方法，通過引入一個輕量雙步微調過程來增強檢索增強語言模型（RALM），可以應用於任何大型語言模型，使其具有檢索能力。第一步專注於微調LLM，使其更好地利用檢索到的信息，而第二步則優化檢索器，以根據LLM的需求檢索更相關的信息。該方法不需要昂貴的模型預訓練階段修改，也不依賴於較低效的後期數據庫集成。在各種零樣本和少樣本學習基準上的測試顯示，RA-DIT實現了前所未有的性能提升，展示了其在知識密集型任務中的有效性，並顯著超越了現有模型在零樣本和少樣本場景中的表現。 | RAG 增強LLM | 2023年10月 |
| [InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining](https://arxiv.org/abs/2310.07713) | InstructRetro基於通過檢索增強預訓練來提升自回歸大型語言模型的方法，推出了其最大的模型Retro 48B。這個模型擴展了一個43B GPT模型，使用額外的1000億個標記進行預訓練，並利用Retro的方法從1.2兆個標記中提取知識，展示了在困惑度和事實準確性方面的顯著改進，同時所需的額外計算資源極少。這一過程不僅展示了檢索增強預訓練的可擴展性，還顯著提升了指令調優和零樣本泛化能力。經過指令微調後的InstructRetro，在各種任務（包括短篇問答、閱讀理解、長篇問答和摘要）上超越了其GPT對應模型，表現出顯著的優勢。有趣的是，研究還發現，去掉編碼器僅使用InstructRetro的解碼器也能取得相當的結果，這表明通過檢索增強預訓練和指令調優優化GPT解碼器是一個有前途的路徑。 | RAG 增強LLM | 2023年10月 |
| [GAR-meets-RAG Paradigm for Zero-Shot Information Retrieval](https://arxiv.org/abs/2310.20158) | GAR-meets-RAG方法創新性地結合了兩種範式——生成增強檢索（GAR）和檢索增強生成（RAG），以應對零樣本信息檢索挑戰，無需目標領域的標註數據。這種方法通過迭代增強檢索和重寫階段，顯著提高了文檔排名中的召回率和精確度，而不需要領域特定的訓練數據。通過將大型語言模型的生成能力與基於嵌入的檢索結合，該方法不僅解決了高召回檢索和高精度排名在零樣本上下文中的常見問題，還在BEIR和TREC-DL數據集上設立了新的基準。在Recall@100和nDCG@10等關鍵指標上取得了高達17%的相對增益，展示了其在零樣本段落檢索任務中的有效性。 | 檢索改進 | 2023年10月 |
| [Retrieve Anything To Augment Large Language Models](https://arxiv.org/abs/2310.07554) | 本文提出了LLM-Embedder，一個統一模型，旨在通過利用檢索增強解決大型語言模型面臨的挑戰。與傳統方法不同，LLM-Embedder優化檢索以滿足不同LLM的需求，使用單一模型。由於不同檢索任務目標的語義關係不同，訓練這一統一模型面臨挑戰。為了克服這一問題，本文提出了優化的訓練方法，包括獎勵制定、穩定知識蒸餾、多任務微調和同質負樣本抽樣。這些策略導致了出色的實驗性能，提供了一個有前途的解決方案，以通過檢索增強提升LLM能力。 | 檢索改進 | 2023年10月 |
| [DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](https://arxiv.org/abs/2310.03714) | DSPy引入了一種系統化方法來開發和優化語言模型（LM）管道，將其抽象為文本轉換圖。這些命令性計算圖允許聲明性模塊調用LM，然後學習通過參數化應用各種技術。DSPy的編譯器優化了這些管道，最大化給定的指標，使得能夠高效地表達和優化複雜的LM管道。案例研究展示了DSPy在多個任務上優於標準提示和專家創建的演示，顯示出即使使用較小的LM模型也能具有競爭力的性能。 | RAG 增強 | 2023年10月 |
| [RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling](https://arxiv.org/abs/2310.10567) | RegaVAE是一種新穎的檢索增強語言模型，旨在解決確定相關信息檢索和有效整合生成過程中的挑戰。通過同時考慮源文本和目標文本，將其編碼到潛在空間中，使用變分自動編碼器（VAE）。利用這一緊湊表示，RegaVAE在文本生成質量和消除幻覺方面超越了現有模型，通過理論分析和跨多個數據集的實驗證明了其有效性。 | RAG 增強LLM | 2023年10月 |
| [Text Embeddings Reveal (Almost) As Much As Text](https://arxiv.org/abs/2310.06816) | 本文探索文本嵌入反轉，旨在從嵌入中重構原始文本。雖然基本模型表現不佳，但多步方法在恢復32個標記的文本輸入方面達到92%的準確性。這一方法在兩個嵌入模型上訓練成功，從臨床筆記中檢索個人信息，如全名，突顯了文本嵌入相關的潛在隱私風險。 | 嵌入 | 2023年10月 |
| [Understanding Retrieval Augmentation for Long-Form Question Answering](https://arxiv.org/abs/2310.12150) | 本文研究了檢索增強語言模型對長篇問答的影響。通過比較使用相同證據文檔生成的答案，分析了檢索增強對不同LLM的影響。研究還檢查了生成答案的各種屬性，並評估了自動判斷證據文檔歸因的方法。提供了有關檢索增強如何影響長篇、知識豐富的文本生成的見解，包括歸因模式和歸因錯誤分析，為該領域未來的研究方向提供了指導。 | RAG 增強LLM | 2023年10月 |
| [Generate rather than Retrieve: Large Language Models are Strong Context Generators](https://arxiv.org/abs/2209.10063) | 這項研究介紹了GenRead，一種處理知識密集型任務（如開放域問答）的新方法，通過利用大型語言模型生成而非檢索上下文文檔。這種方法提示語言模型生成與給定問題相關的上下文，然後使用這些上下文來確定最終答案。此外，GenRead採用了一種基於聚類的提示技術，確保生成文檔的多樣性，涵蓋更廣泛的視角，從而提高答案的準確性。通過在多個任務（包括QA、事實檢查和對話系統）上的嚴格測試，GenRead顯示出顯著超越傳統檢索方法的性能，在TriviaQA和WebQ等基準上取得了顯著更高的精確匹配分數，無需依賴外部知識來源。這標誌著在高效訪問和利用知識方面的一項重大進步。 | RAG 增強 | 2023年9月 |
| [RAGAS: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/abs/2309.15217) | RAGAs介紹了一種評估檢索增強生成系統的新方法，無需人為標註的參考。RAG系統通過從文本數據庫中提取信息來增強語言模型，有助於減少生成文本中的不準確性或「幻覺」。評估這些系統非常複雜，因為需要評估檢索的相關性、LLM使用檢索信息的準確性以及生成文本的整體質量。RAGAs提供了一套綜合指標，快速評估這些方面，無需人工標註，促進了RAG技術的更高效開發和改進。這對於快速發展的大型語言模型領域尤其有價值。 | RAG 評估 | 2023年9月 |
| [RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2308.10633) | RaLLe引入了一個開源框架，旨在提升檢索增強大型語言模型（R-LLM）的開發和評估，特別適用於需要高精度的任務，如問答。針對當前工具缺乏透明度的問題，RaLLe提供了對R-LLM過程中每個步驟的詳細視圖，從檢索到生成。這使開發人員能夠精細化提示，評估不同組件的有效性，並定量衡量模型性能改進。實質上，RaLLe提供了一套完整的工具包，用於提升R-LLM在處理複雜、知識密集型任務方面的效果和準確性。 | RAG 增強LLM | 2023年8月 |
| [RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models](https://arxiv.org/abs/2308.07922) | 本文介紹了RAVEN，一種通過檢索增強來改進編碼器-解碼器語言模型上下文學習的方法。通過分析ATLAS模型，作者指出了訓練和使用之間的不匹配以及上下文可用性有限的挑戰。RAVEN通過整合檢索增強的掩碼和前綴語言建模以及一種稱為上下文融合學習的新技術，解決了這些問題。這種方法在不需要額外訓練或改變模型結構的情況下，增強了少樣本學習能力。測試顯示，RAVEN超越了ATLAS，並在參數更少的情況下，與一些最先進的模型相比表現不俗。這項研究突顯了檢索增強模型在增強上下文學習方面的有效性和潛力，為該領域未來的進步鋪平了道路。 | RAG 增強LLM | 2023年8月 |
| [KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases](https://arxiv.org/abs/2308.11761) | KnowledGPT引入了一個新框架，旨在克服大型語言模型在完整性、時效性、真實性和適應性方面的限制，通過將其與知識庫集成來提升檢索和存儲知識的能力，使LLM更強大和多功能。該框架使用「思想程序」提示生成代碼格式的搜索查詢，促進在知識庫中的精確操作。此外，KnowledGPT允許創建個性化的知識庫，以存儲用戶特定的知識。通過全面測試，KnowledGPT顯示出顯著擴展了LLM能夠回答的問題範圍，利用了公共和個性化知識來源，標誌著使LLM更具知識性和適應性的重大進步。 | 輸入預處理 | 2023年8月 |
| [Learning to Retrieve In-Context Examples for Large Language Models](https://arxiv.org/abs/2307.07164) | 本文介紹了一個新的框架，用於通過迭代訓練密集檢索器來識別高質量示例，提高大型語言模型的上下文學習能力。該框架包括基於LLM反饋訓練的獎勵模型，用於評估候選示例，隨後使用知識蒸餾訓練雙編碼器基於密集檢索器。跨30個任務的實驗結果展示了顯著的性能提升，展示了該框架在看不見任務上的泛化能力。分析顯示，該模型通過檢索具有相似模式的示例提高了性能，始終有利於不同大小的LLM。 | 檢索改進 | 2023年7月 |
| [Active Retrieval Augmented Generation](https://arxiv.org/abs/2305.06983) | 本文探討了如何通過主動檢索增強生成來提高大型語言模型，解決生成內容中常見的事實錯誤或「幻覺」問題。提出的方法FLARE（前瞻性主動檢索增強生成），創新之處在於不僅在生成前檢索信息，而且在生成過程中主動決定何時和檢索什麼。這一過程涉及預測未來的內容需求，並使用這些預測動態檢索相關信息。跨四個長篇知識密集型生成任務的測試顯示，FLARE相比基線方法表現出更優或相當的性能。這種方法在需要多次外部信息生成的長篇文本生成中尤為有用，展示了生成更準確和可靠內容的重大進步。 | 檢索改進 | 2023年5月 |
| [Augmented Large Language Models with Parametric Knowledge Guiding](https://arxiv.org/abs/2305.04757) | 本文提出了一個新穎的參數知識引導（PKG）框架，旨在提高大型語言模型在特定領域任務上的性能。通過集成一個知識引導模塊，PKG允許LLM在不修改原始模型參數的情況下訪問專業知識。這種方法特別有利於增強「黑盒」LLM，這些模型通常不允許修改或微調。PKG框架利用開源模型創建離線知識庫，解決了專有LLM相關的透明度問題和數據隱私問題。PKG的有效性通過在各種知識密集型任務上的顯著性能提升得到展示。 | 領域特定RAG | 2023年5月 |
| [Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory](https://arxiv.org/abs/2305.02437) | 本文介紹了「selfmem」，一個針對檢索增強文本生成的新框架，通過利用模型自身的輸出作為無限內存池，解決了傳統記憶檢索方法的局限性。這種自我記憶方法允許在文本生成任務中進行迭代改進，使用模型生成的內容作為後續生成的新記憶源。跨神經機器翻譯、抽象文本摘要和對話生成任務的測試顯示，selfmem框架表現優異，在多個領域樹立了新基準。研究還詳細分析了該框架的組成部分，為檢索增強文本生成的未來研究提供了寶貴見解。 | 記憶改進 | 2023年5月 |
| [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2305.14283) | 這項研究提出了一個改進檢索增強大型語言模型的框架，通過查詢重寫，名為Rewrite-Retrieve-Read。與僅專注於提升檢索過程或LLM閱讀理解能力的傳統方法不同，該框架強調改進搜索查詢本身，以彌合輸入文本與檢索所需知識之間的鴻溝。通過使用LLM生成初始查詢，然後使用可訓練的小型語言模型進行優化，該方法利用網絡搜索引擎進行更準確的上下文檢索。重寫器進一步通過基於LLM讀者反饋的強化學習進行優化。跨開放域和多選問答任務的展示，這一方法顯示出顯著的性能提升，突顯了其在檢索增強LLM應用中的有效性和可擴展性。| 輸入預處理 | 2023年5月 |
| [Knowledge Graph-Augmented Language Models for Knowledge-Grounded Dialogue Generation](https://arxiv.org/abs/2305.18846) | 本文介紹了SURGE，一個旨在通過將知識圖譜（KG）集成到語言模型的回應過程中，提升知識為基礎的對話生成的框架。SURGE通過檢索KG中的上下文特定子圖並通過創新詞嵌入擾動和對比學習確保生成文本的一致性，提升對話回應的相關性和事實準確性。這種方法保證了對話基於準確和相關的知識。 在OpendialKG和KOMODIS數據集上的測試顯示，SURGE在生成高質量、知識豐富的對話方面顯示了其有效性，解決了對話生成中確保使用相關知識的挑戰。| 檢索改進 | 2023年5月 |
| [Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data](https://arxiv.org/abs/2305.19912) | SANTA模型專注於通過獨特的方法教育語言模型理解結構化內容的細微之處，從而改善結構化數據的檢索。通過對齊結構化和非結構化數據，並聚焦於結構化數據中的實體，SANTA創建了一個共享嵌入空間，提升其檢索能力。這一方法在代碼和產品搜索等任務中展示了令人印象深刻的結果，即使在未直接訓練的場景中也是如此，這得益於其專門的預訓練技術。基本上，SANTA通過教語言模型更好地理解和利用結構化數據的獨特特性脫穎而出。 | 檢索改進 | 2023年5月 |
| [Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In](https://arxiv.org/abs/2305.17331) | 本文介紹了一種新的檢索增強方法，通過增強適應檢索器（AAR）來提升語言模型的性能。與以前緊密集成檢索器和LLM的方法不同，AAR作為靈活的插件，可以在不需要聯合微調的情況下與各種LLM一起使用。這種適應性使AAR能夠提供相關的外部信息，以增強LLM在知識密集型任務上的性能，即使這些LLM未包含在其初始訓練集中。跨多個模型尺寸的測試顯示，AAR顯示出顯著提升LLM從小到非常大的零樣本泛化能力，表明從一個LLM的偏好中學習可以使廣泛的其他LLM受益。這項研究突顯了使檢索增強更普遍適用於不同LLM的潛力。 | 檢索改進 | 2023年5月 |
| [Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy](https://arxiv.org/abs/2305.15294) | 本文介紹了Iter-RetGen，一種通過啟動檢索和生成過程之間的動態交互來增強檢索增強大型語言模型的方法。這種迭代協同作用允許模型基於初始輸出改進其外部知識檢索，然後使用新檢索的信息改進後續生成。與其他方法可能通過交錯檢索與生成施加結構約束不同，Iter-RetGen將檢索到的知識視為一個統一的整體，保持生成的靈活性。在多跳問答、事實驗證和常識推理等任務上的測試顯示，Iter-RetGen不僅高效結合了內參數和外部知識，還顯示出比領先模型更好的性能，同時將檢索和生成開銷降至最低。| RAG 增強LLM | 2023年5月 |
| [Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks](https://arxiv.org/abs/2305.17653) | 本文介紹了PGRA，一個兩階段框架，旨在使用檢索增強方法提升非知識密集型（NKI）任務。不同於以前專注於知識密集型任務的研究，PGRA通過首先使用任務無關的檢索器高效選擇共享靜態索引中的候選證據來解決NKI任務的獨特挑戰。然後，一個提示引導的重排序器將證據調整到具體任務需求。這種方法不僅在性能上超越了現有的檢索增強方法，還展示了在不同任務中的靈活性，標誌著將檢索增強應用於更廣泛NLP任務的一大進步。 | 檢索創新 | 2023年5月 |
| [RET-LLM: Towards a General Read-Write Memory for Large Language Models](https://arxiv.org/abs/2305.14322) | RET-LLM介紹了一個整合通用讀寫記憶單元到大型語言模型中的新框架，解決了它們在顯式存儲和檢索知識方面的限制。該方法基於Davidsonian語義學，使LLM能夠更動態地處理信息，將知識存儲在可擴展、可更新的三元組中。這一框架在問答任務中特別是那些需要理解時間依賴信息的任務上提升了LLM的性能，並在效能和可解釋性方面優於傳統模型。 | 記憶改進 | 2023年5月 |
| [Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources](https://arxiv.org/abs/2305.13269) | Chain-of-Knowledge（CoK）是一個新框架，旨在通過動態整合來自不同來源的基礎信息，提升大型語言模型的性能，旨在生成更準確且無幻覺的內容。CoK通過三個階段操作：從推理準備開始，進入動態知識適應，根據相關領域知識糾正初始推理，並以答案鞏固結束。CoK獨特之處在於能夠利用結構化（如Wikidata、表格）和非結構化知識，由一個能夠處理各種查詢語言的自適應查詢生成器促成。這種方法通過逐步推理糾正過程，確保生成的回答具有穩固的基礎，顯示了在各種知識密集型任務中改進LLM性能的有效性。 | 檢索改進 | 2023年5月 |
| [Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study](https://arxiv.org/abs/2304.06762) | 本文研究了大型自回歸語言模型是否應該進行檢索預訓練。他們使用RETRO，一個可擴展的檢索增強LM，與標準GPT模型進行了全面分析。結果顯示，RETRO在文本生成方面優於GPT，表現出更少的退化和更高的事實準確性，同時毒性更低。此外，RETRO在LM評估工具集的知識密集型任務上表現出色。他們還引入了RETRO++，一個在開放域問答結果上改進的變體，展示了檢索預訓練自回歸LM的潛力。 | RAG 增強LLM | 2023年4月 |
| [UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation](https://arxiv.org/abs/2303.08518) | UPRISE旨在通過引入一種方法自動檢索適合任何零樣本任務的提示，而無需特定於模型或任務的調整，從而提升大型語言模型的多功能性。這種方法在各種任務和模型中表現出色，即使是訓練中未見過的模型，也展示了其減少ChatGPT等模型中幻覺發生的能力。UPRISE的輕量級檢索器使用GPT-Neo-2.7B進行訓練，但在一系列更大的LLM上顯示出顯著性能提升，突顯了其普遍增強LLM性能的潛力。 | LLM 泛化 | 2023年3月 |

