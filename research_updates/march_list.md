| 日期 | 研究名稱 | 摘要 | 主題 |
|-------|-------------|------|------|
| 2024年3月29日  |[Gecko: Versatile Text Embeddings Distilled from Large Language Models](https://arxiv.org/abs/2403.20327) | Gecko 提出了一種新穎的方法，透過將大型語言模型的知識蒸餾到搜尋器中，來建立緊湊且高效的文本嵌入。 Gecko 利用兩階段的蒸餾過程生成多樣且合成配對數據，實現了優越的搜尋效能。  Gecko 關注緊湊性，在大型文本嵌入基準測試 (MTEB) 中，其效能超越了更大的模型和更高維度的嵌入，證明了其在改進資訊檢索任務方面的有效性和潛力。 | 大型語言模型嵌入 |
| 2024年3月28日  |[Grok-1.5](https://x.ai/blog/grok-1.5) | Grok 1.5 提供增強的推理能力，上下文長度達到 128,000 個詞元。 它在編碼、數學相關任務和長上下文理解方面展現了顯著的進步。 Grok-1.5 在 MATH、GSM8K 和 HumanEval 基準測試中的表現有所提升，提供了擴展的記憶容量和出色的搜尋能力。 它建立在自訂的分布式訓練框架之上，為大型語言模型的研究提供高效且可靠的保障。 | 基礎大型語言模型 |
| 2024年3月28日  |[Don't Use Your Data All at Once: sDPO](https://arxiv.org/abs/2403.19270) | sDPO 在語言模型訓練領域中提出了一種新方法，專注於逐步使用偏好數據集。  這種技術透過逐步採用數據集的部分內容，  增强了模型與人類偏好的對齊，  進而得出更精準的參考模型， 並在效能方面超越其他流行的 LLM，  即使是參數更多者。 | 指令微調 |
| 2024年3月28日  |[Jamba: AI21's SSM-Transformer Model](https://www.ai21.com/blog/announcing-jamba) | AI21 實驗室宣布推出 Jamba，一種新穎的 SSM-Transformer 模型，提供 256K 的上下文窗口，旨在平衡 SSM 模型的效率與 Transformer 的能力。  它在各種基準測試中表現出顯著的效能提升。  Jamba 在 Apache 2.0 許可下開源，可在 Hugging Face 上取得，並將很快在 NVIDIA 的 API 目錄中上架，標誌著混合模型架構的重大進步。 | 基礎大型語言模型 |
| 2024年3月28日  |[STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154) | 本論文介紹了 STaR-GATE，  這是一種新穎的方法，  旨在透過訓練語言模型提出澄清性問題來增強其互動技能。  STaR-GATE 採用策略性的師生學習框架，旨在改善模型澄清使用者查詢中的歧義的能力，從而增進溝通效力和準確性，以理解和回應複雜的要求。 | 提示工程 |
| 2024年3月27日  |[Long-form factuality in large language models ](https://arxiv.org/abs/2403.18802v1) | 本論文探討了在大型語言模型生成的開放式主題內容中的真實性挑戰。  它介紹了 LongFact， 一套用於評估長篇文本真實性的提示， 並提出了搜尋增強真實性評估器 (SAFE) 方法。  SAFE 透過多步驟推理過程，  將支援的事實與 Google 搜尋結果進行比較，  評估 LLM 響應中事實的準確性。  研究結果表明，LLM 在超人類真實性評估方面具有潛力，  提供了一種具有成本效益的人工標註替代方案。 | 大型語言模型真實性 |
| 2024年3月27日  |[Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models](https://arxiv.org/abs/2403.18814v1) | Mini-Gemini 提出了一個框架，透過改善視覺詞元、構建高品質的數據集以及引導基於 VLM 的生成，來增強多模態視覺語言模型 (VLM)。  它使用額外的視覺編碼器進行高解析度細化，  而不會增加視覺詞元計數，  旨在增強 VLM 的圖像理解、推理和同步生成能力。  Mini-Gemini 在零樣本基準測試中表現出領先效能，  超越了已開發的私人模型。 | 多模態大型語言模型 |
| 2024年3月27日  |[DBRX](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm) | 一種最先進的開放式大型語言模型，  超越了 GPT-3.5 等已建立的模型，  並與 Gemini 1.0 Pro 競爭。  DBRX 在程式設計和通用 LLM 功能方面表現出色，  具有細粒度的專家混合架構，  可增強訓練和推論效率。  它的規模是 Grok-1 的 40%，  提供更快的推論速度和減少的計算需求。  該模型可在 Hugging Face 上取得，  強調 Databricks 對開放模型的承諾，  並使客戶能夠使用其基礎設施預先訓練 DBRX 類別的模型。 | 基礎大型語言模型 |
| 2024年3月25日  |[AIOS: LLM Agent Operating System ](https://arxiv.org/abs/2403.16971) | AIOS 旨在作為一個 LLM 代理作業系統，  以優化資源分配、  啟用併發執行，  並提供存取控制。  它將 LLM 嵌入到作業系統中，  呈現出一個朝向 AGI 的「有靈魂的作業系統」。  該系統改進了 LLM 代理的效能和效率，  為 AIOS 生態系統開發提供了一個先鋒平台。 | 代理 |
| 2024年3月22日  |[RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners](https://arxiv.org/abs/2403.12373) | 本論文介紹了 RankPrompt，  這是一種新穎的提示方法，  旨在提高 ChatGPT 和 GPT-4 等大型語言模型的推理能力。  與現有的需要人工標註或在不一致情況下失效的解決方案不同，  RankPrompt 使 LLM 能夠透過比較不同的輸出結果來自行對其響應進行排名。  在 11 個推理任務中進行的實驗證明了效能的顯著提升，  最多提高了 13%。  此外，RankPrompt 在開放式評估中 74% 的時間與人類判斷一致，  並表現出對響應變化的穩健性。  這種方法證明了在 LLM 中引出高品質回饋的有效性，  為推進推理能力提供了有希望的途徑。 | 提示工程 |
| 2024年3月22日  |[Mora: Enabling Generalist Video Generation via A Multi-Agent Framework](https://arxiv.org/abs/2403.13248) | Mora 提出了一種新的多代理框架，  旨在解決通用視頻生成能力方面的差距，  目標是與開創性模型 Sora 的效能相匹配。  它利用多個視覺 AI 代理來實現文本到視頻的生成、  圖像到視頻的轉換、  視頻擴展、  編輯、  連接和數位世界模擬，  在各種任務中表現出與 Sora 相似的效能，  但在整體評估時存在明顯差距。 | 多模態大型語言模型 |
| 2024年3月22日  |[LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement](https://arxiv.org/abs/2403.15042) | 這項研究介紹了 LLM2LLM，  這是一種數據增強策略，  利用師生 LLM 框架來提高有限數據任務中的效能。  它包括對學生 LLM 在初始種子數據上進行微調，  識別錯誤，  並使用教師 LLM 根據這些錯誤生成新數據。  這種迭代過程顯著提高了 LLM 在各種數據集中的低數據情況下的效能，  證明了其比傳統微調和其他增強方法有顯著的改善。 | 數據增強 |
| 2024年3月21日  |[Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/pdf/2403.14403.pdf) | 本論文介紹了一種新穎的適應性 QA 框架。  它透過將搜尋增強 LLM 與複雜度級別分類器整合，  動態地為處理不同複雜度的查詢選擇最合適的策略，  從簡單到複雜。  這種方法旨在平衡不同查詢類型中的響應生成效率和準確性，  證明了其比現有模型和適應性搜尋方法有提升。 | RAG |
| 2024年3月20日  |[Evaluating Frontier Models for Dangerous Capabilities](https://arxiv.org/abs/2403.13793) | 本論文開創了「危險能力」評估，  專注於說服、  網路安全、  自我增殖和自我推理等領域，  使用 Gemini 1.0 模型。  雖然沒有發現強烈的危險能力，  但已發現早期預警信號。  該研究旨在推進 AI 模型評估此類能力的科學研究，  為未來的發展做好準備。 | 大型語言模型攻擊 |
| 2024年3月19日  |[Evolutionary Optimization of Model Merging Recipes](https://arxiv.org/abs/2403.13187) | 本論文提出了一種新的方法，  用於透過合併不同的開源模型來自動化強大的基礎模型的建立。  它優化了超過單個模型權重的部分，  促進了跨領域合併，  並實現了最先進的效能，  特別是在日語任務中。  這種方法為自動化模型組合引入了一個新的範例，  為基礎模型開發提供了有效的替代方案。 | 模型合併 |
| 2024年3月19日  |[Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://arxiv.org/abs/2403.12881v1) | 本論文解決了將代理能力整合到大型語言模型中的挑戰，  以提高 NLP 任務中的效能。  它識別了關於代理訓練數據的糾纏、  LLM 的不同學習速度以及現有方法的副作用的關鍵觀察結果。  論文介紹了 Agent-FLAN，  一種用於微調代理語言模型 (Fine-tuning LANguage models for Agents) 的方法，  提出了一種新穎的方法來應對這些挑戰。  透過仔細重新設計訓練語料庫並納入負樣本，  Agent-FLAN 使效能顯著提升，  在多個評估數據集中超越了先前的工作 3.5%。  此外，它減輕了幻覺問題，  並增強了 LLM 的代理能力，  即使模型規模擴大了，  同時略微改善了它們的通用能力。 | 代理、幻覺 |
| 2024年3月18日  |[What Are Tools Anyway? A Survey from the Language Model Perspective](https://zorazrw.github.io/files/WhatAreToolsAnyway.pdf) | 本論文深入探討了工具在增強語言模型文本生成任務效能中的作用。  它解決了圍繞「工具」一詞的模糊性，  並探討了工具如何幫助 LLM。  透過系統性回顧，  論文將工具定義為 LLM 使用的外部程式，  並檢查不同的工具化情景和方法。  實證研究透過衡量基準測試中的計算需求和效能提升，  評估了各種工具化方法的效率。  該調查還確定了 LLM 工具化領域中的挑戰和未來研究方向。 | 代理、工具、調查 |
| 2024年3月17日  |[Grok-1](https://x.ai/blog/grok/model-card) | Grok-1 是一種基於自迴歸 Transformer 的模型，  專為下一詞元預測而設計，  並透過 Grok-0 模型和人類的回饋進行微調。  它於 2023 年 11 月發布，  擁有 8,192 個詞元的上下文長度，  並針對各種 NLP 任務，  例如問答和編碼輔助。  然而，儘管 Grok-1 在資訊處理方面表現出色，  但由於它缺乏獨立的網路搜尋功能，  因此需要人工審查以確保準確性。  儘管可以存取外部資源，  但該模型仍可能會產生幻覺。  它在截至 2023 年第三季度的網際網路和 AI 教師數據上進行訓練，  其效能已在推理任務和外國數學問題上進行評估，  並正在進行早期採用者的測試，  以進一步改進。 | 基礎大型語言模型 |
| 2024年3月15日  |[RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) | 本論文介紹了 Retrieval Augmented FineTuning (RAFT)，  這是一種訓練方法，  旨在增強大型語言模型在特定領域設定中回答問題的能力。  RAFT 利用搜尋增強微調，  使模型能夠有效地將新知識納入其推理過程。  透過訓練模型忽略不相關的文檔（干擾文檔）並引用從檢索到的文檔中引用的相關序列，  RAFT 提高了模型提供準確且連貫響應的能力。  在各種數據集上進行的實驗結果證明了 RAFT 在特定領域搜尋增強生成中的有效性，  為在特定領域的背景下增強預先訓練的 LLM 提供了有價值的後訓練配方。 | RAG、微調 |
| 2024年3月14日  |[Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539) | 本論文揭示，  即使限制對專有大型語言模型的 API 存取，  也可以從少數 API 查詢中推斷出大量的專有資訊。  透過利用大多數現代 LLM 中存在的 softmax 瓶頸，  研究證明了揭示模型架構隱藏方面並取得完整詞彙輸出的能力。  這包括有效地發現隱藏的模型大小、  識別不同的模型更新，  以及估計輸出層參數。  對 OpenAI 的 gpt-3.5-turbo 進行的實證調查顯示，  其嵌入大小約為 4,096。  論文最後討論了 LLM 提供者可以採取的措施來減輕此類攻擊，  並建議將這些功能視為增強透明度和問責制的機會，  而不是漏洞。 | 大型語言模型攻擊、隱私 |
| 2024年3月14日  |[Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/abs/2403.09629) | 本論文介紹了 Quiet-STaR，  這是一種旨在使語言模型學習生成理由來解釋未來文本的方法，  從而提高其預測能力。  Quiet-STaR 建立在自學推理器 (STaR) 框架之上，  允許 LLM 推斷任意文本中未明確說明的理由。  解決的主要挑戰包括計算成本、  LLM 初始對生成內部想法的不熟悉程度，  以及預測超出單個詞元的範圍。  所提出的方法涉及詞元級平行採樣、  用於指示想法邊界的可學習詞元，  以及擴展的教師強制技術。  Quiet-STaR 導致 LLM 在 GSM8K 和 CommonsenseQA 等任務中的效能顯著提升，  而無需微調，  標誌著 LLM 朝向更通用且可擴展的推理能力邁出了一步。 | 提示工程 |
| 2024年3月14日  |[MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://arxiv.org/abs/2403.09611) | 本論文探討了高性能多模態大型語言模型 (MLLM) 的開發，  並調查了各種架構組成部分和數據選擇的重要性。  透過對圖像編碼器、  視覺語言連接器和預訓練數據選項進行精細的消融，  發現了幾項關鍵的設計洞察。  例如，  仔細整合圖像-標題、  交錯圖像-文本和純文本數據被證明對於在多個基準測試中實現最先進的少樣本結果至關重要。  此外，  強調了圖像編碼器中圖像解析度和詞元計數的影響，  而視覺-語言連接器設計被發現相對不那麼重要。  擴展所提出的方法會產生 MM1，  這是一個多模態模型系列，  具有高達 300 億個參數，  包括密集模型和專家混合變體。  MM1 在各種多模態基準測試中實現了最先進的預訓練指標和競爭性效能，  得益於由大規模預訓練提供的增強的上下文學習和多圖像推理能力。 | 多模態大型語言模型 |
| 2024年3月13日  |[Knowledge Conflicts for LLMs: A Survey](https://arxiv.org/abs/2403.08319) | 這份調查深入探討了大型語言模型遇到的知識衝突，  重點關注上下文知識和參數知識的融合。  它識別了三種類型的衝突：  上下文-記憶、  上下文間和記憶內衝突，  這些衝突會顯著影響 LLM 的可信度和效能，  特別是在存在噪聲和錯誤資訊的真實世界情景中。  透過分類、  探討原因、  觀察 LLM 的行為，  以及回顧現有解決方案，  該調查旨在提供洞察力，  以增強 LLM 的穩健性，  作為推進該領域研究的寶貴資源。 | 大型語言模型穩健性 |
| 2024年3月12日  |[MoAI: Mixture of All Intelligence for Large Language and Vision Models](https://arxiv.org/abs/2403.07508) | MoAI 提出了一種創新方法，  將大型語言和視覺模型的優勢與專門的計算機視覺模型結合起來，  用於分割和 OCR 等任務。  透過利用輔助視覺資訊，  並透過獨特的模組化設計將其與語言特徵融合，  MoAI 在各種零樣本視覺語言任務中實現了優越的效能，  特別是在真實世界場景理解中，  而無需增加模型大小或需要額外的視覺指令數據集。 | 多模態大型語言模型 |
| 2024年3月12日  |[Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM](https://arxiv.org/abs/2403.07816) | 本論文探討了有效訓練大型語言模型以在多個專門領域中表現出色的方法，  例如編碼、  數學推理和世界知識。  介紹了 Branch-Train-MiX (BTX)，  這種方法從一個種子模型開始，  並分支成平行訓練專家，  減少了通訊成本。  訓練完畢後，  BTX 將專家的前饋參數組合成專家混合 (MoE) 層，  然後進行 MoE 微調階段以學習詞元級路由。  BTX 包括兩個特殊情況：  Branch-Train-Merge，  它缺少 MoE 微調階段，  以及稀疏向上循環，  它跳過異步訓練。  結果表明，  與其他方法相比，  BTX 提供了最佳的準確性-效率權衡。 | MoEs、基礎大型語言模型 |
| 2024年3月11日  |[Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634) | 本論文介紹了第一個模型竊取攻擊，  能夠從 OpenAI 的 ChatGPT 或 Google 的 PaLM-2 等黑盒生產語言模型中提取精確的資訊。  透過利用典型的 API 存取，  該攻擊可以恢復變壓器模型的嵌入投影層，  包括對稱性。  值得注意的是，  該攻擊以低於 20 美元的價格實現了這一點，  分別揭示了 OpenAI 的 Ada 和 Babbage 模型的隱藏維度為 1024 和 2048。  此外，  還恢復了 gpt-3.5-turbo 模型的準確隱藏維度大小，  估計在查詢中花費低於 2,000 美元的成本即可取回整個投影矩陣。  論文最後討論了潛在的防禦措施和緩解措施，  以及可能擴展攻擊的未來工作的影響。 | 大型語言模型攻擊 |
| 2024年3月8日  |[RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](https://arxiv.org/abs/2403.05313) | 本論文介紹了搜尋增強思想 (RAT)，  這是一種旨在增強大型語言模型在長時程生成任務中的推理和生成能力，  同時減少幻覺的方法。  RAT 透過在每個步驟中納入相關的檢索資訊，  來迭代地修正一系列思想。  RAT 應用於 GPT-3.5、  GPT-4 和 CodeLLaMA-7b，  在各種任務中顯著提高了效能，  編碼生成的平均評分得分提高了 13.63%、  數學推理提高了 16.96%、  創意寫作提高了 19.2%、  具身任務規劃提高了 42.78%。 | RAG、提示工程 |
| 2024年3月7日  |[Common 7B Language Models Already Possess Strong Math Capabilities](https://arxiv.org/abs/2403.05313) | 這項研究表明，  較小的 70 億參數語言模型，  特別是 LLaMA-2，  已經表現出強大的數學能力，  挑戰了之前認為此類能力需要非常大的模型或大量以數學為中心的預訓練的假設。  透過利用合成數據和縮放策略，  該研究顯著提高了模型的數學解題準確性，  超越了以前的基準測試，  證明了透過適當的訓練，  即使是相對較小的模型也能夠實現出色的數學效能。 | 領域特定大型語言模型 |
| 2024年3月7日  |[ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](https://arxiv.org/abs/2403.03853) | 本論文介紹了 ShortGPT，  它證明了大型語言模型層之間存在高度的冗餘性。  作者透過一個稱為區塊影響 (BI) 的指標來評估每個層的必要性，  提出了一個簡單的修剪方法。  他們的方法透過移除冗餘層來簡化模型，  在不損害模型效能的情況下顯著提高了效率，  標誌著優化 LLM 架構的進展。 | 較小型語言模型 |
| 2024年3月7日  |[Can Large Language Models Reason and Plan?](https://arxiv.org/abs/2403.04121) | 本論文質疑大型語言模型是否能夠執行自我批評並修正其錯誤的猜測，  這是人類偶爾會表現出的能力。  這個問題突出了人類認知過程與 LLM 的計算機制之間的截然不同之處，  挑戰了關於兩者在推理和自我修正能力方面相等的假設。 | 提示工程 |
| 2024年3月6日  |[GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection](https://arxiv.org/abs/2403.03507) | 本論文提出了一種新穎的訓練策略，  稱為 GaLore。  這種方法旨在透過實施梯度低秩投影來減少訓練大型語言模型的記憶體需求，  顯著減少優化器狀態所使用的記憶體，  而不會犧牲效能。  它允許在消費級 GPU 上有效地訓練大型模型，  標誌著 AI 模型訓練可及性的重大進步。 | 記憶體優化 |
| 2024年3月5日  |[KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101) | 這項工作介紹了 KnowAgent，  這是一種旨在透過納入明確的動作知識來增強大型語言模型規劃能力的新穎方法。  這種整合旨在解決當前模型缺乏內建動作知識，  導致規劃幻覺的不足。  KnowAgent 使用動作知識庫和自我學習策略來引導規劃軌跡，  從而導致在各種領域中更準確有效地解決問題。 | 代理 |
| 2024年3月4日  |[The Claude 3 Model Family: Opus, Sonnet, Haiku](https://paperswithcode.com/paper/the-claude-3-model-family-opus-sonnet-haiku) | Claude 的這份技術報告介紹了 Claude 3，  這是一個新的大型多模態模型系列，  旨在滿足 AI 領域中的各種需求。  Claude 3 包括三個不同的產品：  Opus、  Sonnet 和 Haiku，  每個產品都針對能力、  速度和成本效益方面的不同需求量身打造。  所有模型都具有用於處理圖像數據的視覺功能。  在基準評估中，  Claude 3 系列表現出強大的效能，  在推理、  數學和編碼任務中樹立了新標準。  Claude 3 Opus 在多項評估中取得了最先進的結果，  而 Haiku 在基於文本的任務中的效能與 Claude 2 相當，  Sonnet 和 Opus 則顯著超越了它。  此外，  這些模型在非英語語言中的流利性有所增強，  提高了其在全球受眾中的多功能性。  該報告還包括對評估的深入分析，  重點關注核心能力、  安全考量、  社會影響和對負責任縮放政策的遵守。 | 基礎大型語言模型 |

