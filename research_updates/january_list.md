## :star:2024年1月最佳生成AI論文

| Date        | Name                                                                                                                  | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Topics                  |
| ----------- | --------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- |
| 2024年1月31日 | [Large Language Models for Mathematical Reasoning: Progresses and Challenges](https://arxiv.org/html/2402.00157v1)                                           | 本調查深入探討大型語言模型在數學問題解決中的應用，涵蓋各種問題類型、數據集、技術、因素和挑戰。全面探索了這一新興領域的進展和障礙，提供了對當前狀況和未來方向的見解。本調查提供了對LLM在數學推理中角色的全方位視角，旨在引導這一快速發展領域的未來研究。                                                                                             | Task Specific LLMs      |
| 2024年1月29日 | [Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884)                                                                             | 為了解決檢索增強生成模型的穩健性問題，提出了Corrective Retrieval Augmented Generation（CRAG）。CRAG包含一個輕量級的檢索評估器來評估文件品質，並根據信心水平觸發不同的檢索動作。它通過大規模網頁搜索擴展檢索結果，並使用分解-再重組算法來聚焦關鍵資訊。實驗表明，CRAG在各種生成任務中有效提升了基於RAG的方法。                             | RAG                     |
| 2024年1月29日 | [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://arxiv.org/abs/2401.15947)                                                         | 本研究介紹了MoE-Tuning，一種針對大型視覺語言模型的訓練策略，通過構建具有恆定計算開銷的稀疏模型來解決現有擴展方法的計算成本問題。還提出了MoE-LLaVA，一種基於MoE的稀疏LVLM架構，在部署期間僅激活前k個專家。實驗結果表明，MoE-LLaVA在各種視覺理解和物件幻覺基準上顯著提升性能，為更高效的多模態學習系統提供了見解。               | MoE Models              |
| 2024年1月29日 | [The Power of Noise: Redefining Retrieval for RAG Systems](https://arxiv.org/abs/2401.14887)                                                               | 本研究檢查了資訊檢索組件對檢索增強生成系統的影響，補充了先前研究中對RAG系統中LLM生成方面的關注。通過分析文件相關性、位置和上下文大小等特徵，研究揭示了意外的見解，如包括不相關文件的驚人性能提升。這些發現強調了開發專門策略以整合檢索與語言生成模型的重要性，為該領域的未來研究提供指導。 | RAG                     |
| 2024年1月24日 | [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://arxiv.org/abs/2401.13601)                                                           | 本文對多模態大型語言模型（MM-LLMs）進行了全面調查，這些模型增強了現成的LLM以支持多模態輸入或輸出。它概述了設計公式，介紹了26個現有的MM-LLMs，回顧了它們在主流基準上的表現，並總結了關鍵訓練秘訣。探索了MM-LLMs的有前景方向，並提供了一個實時跟踪網站以了解最新發展，旨在促進MM-LLMs領域的持續進步。                                                                | Multimodal LLMs         |
| 2024年1月23日 | [Red Teaming Visual Language Models](https://arxiv.org/abs/2401.12915)                                                                                     | 介紹了一個新的紅隊數據集RTVLM，用於評估視覺語言模型（VLMs）在生成有害或不準確內容方面的性能。它涵蓋了忠實性、隱私、安全性和公平性方面的10個子任務。分析揭示了著名開放原始碼VLMs之間的顯著性能差距，促使探索紅隊對齊技術。將紅隊對齊應用於LLaVA-v1.5增強了模型性能，表明該領域需要進一步發展。                                                         | Red-Teaming             |
| 2024年1月23日 | [Lumiere: A Space-Time Diffusion Model for Video Generation](https://arxiv.org/abs/2401.12945)                                                            | Lumiere被介紹為一種文本到影片的擴散模型，旨在合成真實且連貫的影片運動。它採用空間-時間U-Net架構，在一次通過中生成整個影片時長，實現全域時間一致性。通過空間和時間的降採樣和升採樣，並利用預訓練的文本到圖像擴散模型，Lumiere實現了最先進的文本到影片生成結果，輕鬆促進各種內容創作和影片編輯任務。                                                             | Diffusion Models        |
| 2024年1月22日 | [WARM: On the Benefits of Weight Averaged Reward Models](https://arxiv.org/abs/2401.12187)                                                                | 針對大型語言模型的人類反饋強化學習可能導致獎勵黑客問題，提出了Weight Averaged Reward Models（WARM），即在權重空間中平均多個微調的獎勵模型。WARM在分佈轉變和偏好不一致的情況下提高了效率和可靠性，增強了LLM預測的品質和對齊度。在摘要任務上的實驗表明，使用WARM的RL微調模型優於單一RM對應物。                                 | Instruction Tuning      |
| 2024年1月18日 | [Self-Rewarding Language Models](https://arxiv.org/abs/2401.10020)                                                                                        | 本文介紹了自我獎勵語言模型，其中語言模型本身在訓練期間通過LLM-as-a-Judge提示提供獎勵。通過迭代訓練，模型不僅提高了其指令遵循能力，還增強了生成高品質獎勵的能力。使用這種方法微調Llama 2 70B，產生的模型在AlpacaEval 2.0排行榜上超越了現有系統，展示了在性能軸上持續改進的潛力。                                                                 | Prompt Engineering      |
| 2024年1月16日 | [Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](https://arxiv.org/abs/2401.08500)                                        | AlphaCodium被提出為一種新的大型語言模型程式碼產生方法，強調基於測試的多階段、面向程式碼的迭代流程，專為程式碼任務量身定制。在CodeContests數據集上測試，AlphaCodium一致提高了LLM性能，相較於直接提示顯著提升了準確性。從這種方法中得出的原則和最佳實踐被認為廣泛適用於一般程式碼產生任務。                                                                                                                    | Code Generation         |
| 2024年1月13日 | [Leveraging Large Language Models for NLG Evaluation: A Survey](https://arxiv.org/html/2401.07103v1)                                                        | 本調查深入探討了利用大型語言模型評估自然語言生成，提供了一個全面的分類法來組織現有的評估指標。它批判性地評估了基於LLM的方法，強調了它們的優勢、局限性和未解決的挑戰，如偏見和領域特異性。該調查旨在為研究人員提供見解，並倡導更公平和更先進的NLG評估技術。                                                                                                                    | Evaluation              |
| 2024年1月12日 | [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs](https://arxiv.org/html/2401.06373v1)      | 本文通過將大型語言模型視為類人溝通者，研究如何通過說服來破解它們，探索了一種新的AI安全視角。它引入了一個說服分類法，並將其應用於生成可解釋的說服性對抗提示（PAP），在GPT-3.5和GPT-4等LLM上實現了高攻擊成功率。該研究還強調了現有防禦措施中的漏洞，並倡導更根本的緩解策略來應對互動式LLM的攻擊。                                                              | Red-Teaming             |
| 2024年1月11日 | [Seven Failure Points When Engineering a Retrieval Augmented Generation](https://arxiv.org/abs/2401.05856) System                                      | 本文探討了通過檢索增強生成（RAG）系統將語義搜索能力整合到應用中的問題。基於各個領域的案例研究，確定了RAG系統設計中的七個失敗點。主要收穫包括在運行期間驗證RAG系統的可行性以及系統穩健性的演變。本文最後提出了增強RAG系統有效性的潛在研究方向。 | RAG              |

| 10 Jan 2024 | [TrustLLM: Trustworthiness in Large Language Models](https://arxiv.org/abs/2401.05561)                                                                     | 本文檢視大型語言模型（如ChatGPT）的可信度，提出了原則和基準。它評估了16個大型語言模型，發現可信度與效能之間存在相關性，但也指出專有模型優於開放原始碼模型的問題。本文強調了在模型和底層技術方面透明度的重要性，以進行可信度分析。                                                                                                                                                                                    | Alignment               |
| 9 Jan 2024  | [Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding](https://arxiv.org/abs/2401.04398)                                          | Chain-of-Table框架提出在推理鏈中明確利用表格數據來增強基於表格的推理任務。它通過上下文學習指導大型語言模型迭代生成操作並更新表格，允許基於先前結果進行動態規劃。這種方法在各種表格理解基準上達到了最先進的性能，展示了其在增強基於大型語言模型的推理方面的有效性。                                                                                                      | Prompt Engineering, RAG |
| 8 Jan 2024  | [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)                                              | 本文介紹了MoE-Mamba，一種結合專家混合（MoE）與序列狀態空間模型（SSMs）的模型，以增強擴展性和性能。MoE-Mamba超越了Mamba和Transformer-MoE，在保持Mamba對Transformer的推論增益的同時，以更少的訓練步驟達到了類似Transformer的性能。                                                                                                                                                                                                                                        | MoE Models              |
| 4 Jan 2024  | [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM](https://arxiv.org/abs/2401.02994)                                      | 本文探討了是否可以通過結合較小的聊天AI模型來匹配或超越單個大型模型（如ChatGPT）的性能，而不需要大量計算資源。通過在Chai研究平台上的實證證據和A/B測試，"blending"方法展示了有可能與更大模型的能力相媲美或超越的潛力。                                                                                                                                                                                                          | Smaller Models          |

