| 日期        | 名稱                                                                                                                                                                                                                                                                                                     | 概要                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 主題                         |
| ----------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------ |
| 2024年2月28日 | [Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://arxiv.org/pdf/2402.17177.pdf)                                                                                                                                                                 | 這篇論文深入分析了由OpenAI推出的Sora，一種文本到視頻生成的人工智慧模型。它探討了Sora的演變、基礎技術、跨行業的多樣化應用及其對創意和生產力的潛在影響。論文還討論了視頻生成中的安全和偏見挑戰，以及Sora和類似模型的未來方向，展望了人類與AI在視頻製作中的協作創新。請注意，這篇論文並非由Sora的創建者撰寫，而是一群研究人員的逆向工程成果。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 多模態模型                    |
| 2024年2月28日 | [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://arxiv.org/pdf/2402.14658.pdf)                                                                                                                                                                                  | 這篇論文介紹了OpenCodeInterpreter，一系列開源代碼系統，旨在通過整合執行能力和迭代改進來解決現有開源模型在代碼生成方面的局限性。它利用了包含68K多回合互動的CodeFeedback數據集，將執行和人類反饋相結合進行動態代碼改進。在關鍵基準上的評估表明，OpenCodeInterpreter在HumanEval和MBPP基準上達到了與GPT-4接近的準確性，有效地縮小了開源和專有代碼生成系統之間的差距。                                                                                                                                                                                                                                                                                                                                                                                                                       | 特定任務的LLM, 評估            |
| 2024年2月27日 | [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://arxiv.org/pdf/2402.17753.pdf)                                                                                                                                                                                                     | 這篇論文介紹了一個機器-人類流水線，用於生成高品質、超長期對話，跨度達到35次對話，使用大型語言模型和檢索增強生成技術。對話基於人物設定和時間事件圖，每個代理都能分享和回應圖像。最終數據集LOCOMO包含平均300輪對話。評估基準測量了模型的長期記憶，揭示了LLM在理解長時間對話和掌握長期時間動態方面的挑戰。雖然長上下文LLM或RAG等策略有所改進，但模型仍落後於人類表現。                                                                                                                                                                                                                                                                                                                                                                                                                 | RAG, 基準, 長上下文             |
| 2024年2月27日 | [When Scaling Meets LLM Finetuning: The Effect of Data, Model, and Finetuning Method](https://arxiv.org/pdf/2402.17193.pdf)                                                                                                                                                                              | 這篇論文研究了LLM不同微調方法的縮放特性。通過系統實驗，探討了模型大小、預訓練數據量和微調數據量等各種縮放因素對微調性能的影響。結果表明，微調數據量和其他因素之間存在基於乘法的縮放定律，其中模型縮放比預訓練數據縮放帶來更多收益。此外，最佳微調方法因任務和微調數據而異。這些發現旨在增強對LLM微調方法的理解和發展。                                                                                                                                                                                                                                                                                                                                                                                                                         | 微調                           |
| 2024年2月27日 | [The Era of 1-bit LLMs:](https://arxiv.org/pdf/2402.17764.pdf) [All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764.pdf)                                                                                                                                                         | 這篇論文介紹了BitNet b1.58，一個每個參數都是三元 {-1, 0, 1} 的變體，能在困惑度和最終任務性能上匹配全精度的Transformer LLM，同時具有顯著的成本效益。這種1.58-bit的LLM樹立了高性能、成本效益模型的新標準，並開創了新的計算範式和針對1-bit LLM優化的硬體設計機會。                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 成本效益的LLM                  |
| 2024年2月26日 | [Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts](https://arxiv.org/pdf/2402.16822.pdf)                                                                                                                                                                                             | 這篇論文介紹了Rainbow Teaming，一種多樣生成對抗提示的方法，以增強LLM的魯棒性。通過將提示生成框定為質量-多樣性問題，它揭示了各領域的漏洞，包括安全性、問答和網絡安全。此外，通過對Rainbow Teaming生成的合成數據進行微調，可以在不影響通用能力的情況下提高安全性，提供了一條開放式自我改進的路徑。                                                                                                                                                                                                                                                                                                                                                                                                                       | 紅隊測試                       |
| 2024年2月26日 | [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://arxiv.org/pdf/2402.16837.pdf)                                                                                                                                                                                                    | 這項研究探討了LLM在處理複雜提示時是否進行潛在的多跳推理。通過分析個別跳步及其共現性，研究了LLM如何識別和利用橋接實體來完成提示。結果顯示，在某些關係類型中存在強烈的潛在多跳推理證據，其中推理路徑在超過80%的提示中被使用。然而，這種利用因情境而異，雖然第一跳的證據充分，但第二跳的證據較為適中。此外，隨著模型大小的增加，第一跳的利用呈現出擴展趨勢，但第二跳沒有，這表明未來LLM開發中存在潛在挑戰和機會。                                                                                                                                                                                                                                                                                                                                   | 評估                           |
| 2024年2月26日 | [Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs](https://arxiv.org/pdf/2402.14740.pdf)                                                                                                                                                                                  | 這篇論文討論了從人類反饋中進行強化學習（RLHF）對於大型語言模型（LLM）對齊的重要性。雖然近端策略優化（PPO）被廣泛使用，但其高計算成本和超參數敏感性帶來挑戰。研究提出了簡化的REINFORCE風格優化變體，顯示出優於PPO和其他方法（如DPO和RAFT）的性能。研究表明，適應LLM對齊特徵可以實現高效的在線RL優化。                                                                                                                                                                                                                                                                                                                                                                                                                    | 指令調整                       |
| 2024年2月23日 | [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/pdf/2402.09727.pdf)                                                                                                                                                                                              | 這篇論文介紹了ReadAgent，一種創新的LLM系統，顯著擴展了有效上下文長度，實驗中達到20倍。模仿人類閱讀，ReadAgent策略性地儲存和壓縮內容成「摘要記憶」，以便在需要時高效檢索。對長文檔閱讀任務的評估顯示，ReadAgent在提升性能的同時，將有效上下文窗口擴展了3到20倍。                                                                                                                                                                                                                                                                                                                                                                                                                                                        | LLM代理                        |
| 2024年2月22日 | [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases](https://arxiv.org/pdf/2402.14905.pdf)                                                                                                                                                                                | 這篇論文針對移動設備上的高效LLM需求，重點關注參數少於十億的模型。與數據量和參數數量決定模型品質的看法相反，研究強調了模型架構的重要性。引入MobileLLM，利用深薄架構，該模型在準確性上明顯超過了先前的最新模型。此外，MobileLLM-LS引入了塊狀權重共享，在延遲幾乎不變的情況下進一步提升了準確性，突顯了小型模型在設備端應用中的潛力。                                                                                                                                                                                                                                                                                                                                                                           | 小型模型                       |
| 2024年2月22日 | [Stable Diffusion 3](https://stability.ai/news/stable-diffusion-3)                                                                                                                                                                                                                                        | [Stability.ai](http://Stability.ai) 宣布其最新的文本生成圖像模型Stable Diffusion 3的早期預覽，具有顯著改進的多主題提示、圖像品質和拼寫能力。現在開放了早期訪問的等待名單，允許用戶提供見解以改進性能和安全性，然後再公開發布。該套件參數範圍從800M到8B，提供延展性選項以滿足各種創意需求。強調安全和負責任的AI實踐，[Stability.ai](http://Stability.ai) 已實施了許多保障措施，並繼續與研究人員和專家合作，以確保在開發和部署過程中的完整性。                                                                                                                                                                                                                                                                                                               | 多模態模型                     |
| 2024年2月21日 | [Coercing Large Language Models (LLMs) to Do and Reveal (Almost) Anything](https://arxiv.org/pdf/2402.14020.pdf)                                                                                                                                                                                            | 這篇論文擴展了對LLM的對抗性攻擊範疇，超越了「越獄」，強調了各種攻擊面和目標。通過具體示例，論文分類了誘發意外行為的攻擊，如誤導、模型控制、拒絕服務和數據提取。控制實驗揭示了許多攻擊源自於具備代碼能力的預訓練和LLM詞彙中的「故障」標記，強調了安全措施的重要性。                                                                                                                                                                                                                                                                                                                                                                                                                                                  | 紅隊測試                       |
| 2024年2月21日 | [LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens](https://arxiv.org/pdf/2402.13753.pdf)                                                                                                                                                                                                      | 這篇論文介紹了LongRoPE，將預訓練LLM的上下文窗口擴展到令人印象深刻的2048k標記，克服了當前擴展上下文窗口的限制。關鍵創新包括利用位置插值中的非均勻性，逐步擴展策略，並進行調整以恢復短上下文窗口性能。大量實驗證明了LongRoPE在各種任務中的有效性，模型保留了原有架構並對位置嵌入進行了微小修改。                                                                                                                                                                                                                                                                                                                                                                                    | 長上下文, 嵌入                  |
| 2024年2月21日 | [Gemma: Open Models Based on Gemini Research and Technology](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)                                                                                                                                                                          | 這項工作介紹了Gemma，一系列基於Gemini研究和技術的輕量級、最先進的開源模型。Gemma模型在語言理解、推理和安全性方面展示了強大的性能。我們發布了兩個模型大小（20億和70億參數），並提供了預訓練和微調檢查點。Gemma在18個文本基準任務中有11個超越了同類開源模型，我們還提供了關於模型開發的詳細描述和全面的安全性和責任評估。我們相信負責任地發布LLM對於提高前沿模型的安全性和促進LLM創新浪潮至關重要。                                                                                                                                                                                                                                                                                                                         | 基礎LLM                        |
| 2024年2月21日 | [Large Language Models for Data Annotation: A Survey](https://arxiv.org/pdf/2402.13446.pdf)                                                                                                                                                                                                                | 這篇論文專注於利用先進的LLM（如GPT-4）來自動化數據標註，這是一個機器學習中的勞動密集型過程。它提供了對LLM為基礎的數據標註、評估LLM生成的標註以及使用LLM生成標註進行學習的洞見。調查包括方法論分類，回顧學習策略，並討論挑戰和局限。旨在指導研究人員和從業者，促進使用最新LLM在數據標註方面的進步。                                                                                                                                                                                                                                                                                                                                                                                                           | 特定任務的LLM                  |
| 2024年2月21日 | [In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss](https://arxiv.org/pdf/2402.10790.pdf)                                                                                                                                                                                      | 這篇論文介紹了BABILong，一個設計用來評估生成型Transformer模型處理長文檔能力的基準。雖然常見方法對序列的有效性僅限於10^4元素，但通過增加遞迴記憶進行GPT-2的微調，使其能夠處理多達11 × 10^6元素的任務。這一成就代表了處理長序列能力的顯著提升，標誌著迄今為止任何神經網絡模型所處理的最長輸入。                                                                                                                                                                                                                                                                                                                                                                        | 基準, 長上下文                 |
| 2024年2月20日 | [Large Language Models: A Survey](https://arxiv.org/pdf/2402.06196.pdf)                                                                                                                                                                                                                                   | 這篇論文對自2022年11月ChatGPT發布以來的LLM進行了全面回顧。討論了主要的LLM家族（如GPT、LLaMA、PaLM），它們的特徵、貢獻和局限性，以及構建和增強LLM的技術。此外，它還調查了數據集、評估指標以及在代表性基準上對流行LLM的性能比較。論文最後強調了LLM領域的開放挑戰和未來研究方向。                                                                                                                                                                                                                                                                                                                                                                                                                               | LLM調查                        |
| 2024年2月19日 | [LongAgent: Scaling Language Models to 128k Context Through Multi-Agent Collaboration](https://arxiv.org/pdf/2402.11550.pdf)                                                                                                                                                                                | 這篇論文介紹了LongAgent，一種利用多代理協作將LLM（如LLaMA）擴展到處理長達128K標記文本的方法。LongAgent利用一個領導者來解釋用戶意圖並協調成員獲取資訊。為了解決因幻覺引起的響應不準確問題，成員之間的通訊機制通過資訊共享來解決衝突。實驗結果顯示，LongAgent在128k長文本檢索和多跳問答等任務上優於GPT-4。                                                                                                                                                                                                                                                                                                                                                                               | LLM代理                        |
| 2024年2月19日 | [LoRA+: Efficient Low Rank Adaptation of Large Models](https://arxiv.org/pdf/2402.12354.pdf)                                                                                                                                                                                                               | 這篇論文指出使用低秩適應（LoRA）對大寬度（嵌入維度）模型進行微調時的次優性能，原因在於以相同的學習率更新適配器矩陣A和B。通過在提出的算法LoRA+中為A和B設置不同的學習率並保持固定比例，可以矯正LoRA的次優性能。大量實驗表明，LoRA+在相同計算成本下提高了性能（1%−2%的提升）和微調速度（最高達2倍加速）。                                                                                                                                                                                                                                                                                                                                                                                                    | PEFT                           |
| 2024年2月15日 | [Generative Representational Instruction Tuning](https://arxiv.org/pdf/2402.09906.pdf)                                                                                                                                                                                                                      | 這篇論文介紹了生成表示指令調整（GRIT），使大型語言模型能夠在生成和嵌入任務中均表現出色，通過指令區分這兩者。GRITLM 7B在大規模文本嵌入基準（MTEB）上創下了新的記錄，在生成任務上超越了所有同尺寸模型。擴展到GRITLM 8X7B後，進一步超越了所有開源生成語言模型，同時仍是最好的嵌入模型之一。GRIT統一了生成和嵌入訓練，沒有性能損失，顯著加速了長文檔的RAG超過60%。提供了模型和代碼。                                                                                                                                                                                                                                                                                                                                           | RAG, 指令調整                  |
| 2024年2月15日 | [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/pdf/2402.10200.pdf)                                                                                                                                                                                                                      | 該研究通過改變解碼過程來增強大型語言模型的推理能力，而不需要明確的提示，從而揭示內在的連鎖思維（CoT）推理路徑。這種方法避免了手動提示工程，評估了內在推理能力，並將CoT存在與解碼答案的高信心相關聯。跨基準的大量實證研究顯示，與標準貪婪解碼相比，性能有顯著提高。                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 提示工程                       |
| 2024年2月15日 | [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf)                                                                                                                                          | 該報告介紹了Gemini 1.5 Pro，一個高度高效的多模態模型，在回憶和推理大量上下文（包括長文檔和視頻）方面表現出色。它在各項任務上達到近乎完美的回憶能力，超越了先前的最新模型，並展示了對Kalamang等罕見語言的出色翻譯能力。                                                                                                                                                                                                                                                                                                                                                                                                                                             | 基礎LLM                        |
| 2024年2月15日 | [Revisiting Feature Prediction for Learning Visual Representations from Video](https://scontent-sjc3-1.xx.fbcdn.net/v/t39.2365-6/427986745_768441298640104_1604906292521363076_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=buAjC_nNnqUAX_pFLGu&_nc_ht=scontent-sjc3-1.xx&oh=00_AfArQSha7RDlNPxQSmkYElwmG3p5BwlKUM4tUroqmW5d_A&oe=65E670B1) | 這篇論文介紹了V-JEPA，一個僅使用視頻數據進行特徵預測目標訓練的視覺模型集合，不依賴預訓練的圖像編碼器、文本、負面樣本或重建。這些模型在200萬個視頻上進行訓練，並在下游圖像和視頻任務中進行評估，展示了在運動和外觀任務上均出色的視覺表示能力，且不需要模型參數的調整。最大的模型ViT-H/16僅使用視頻訓練，在Kinetics-400、Something-Something-v2和ImageNet1K數據集上取得了令人印象深刻的性能。                                                                                                                                                                      | 多模態LLM                      |
| 2024年2月13日 | [World Model on Million-Length Video and Language with Ring Attention](https://arxiv.org/pdf/2402.08268.pdf)                                                                                                                                                                                                 | 這篇論文提出了一種聯合建模方法，通過視頻序列來增強語言模型的理解能力，以應對複雜、長篇任務的挑戰。它編撰了一個大型多樣化的視頻和書籍數據集，使用RingAttention技術對長序列進行訓練，並逐漸增加上下文大小。關鍵貢獻包括訓練了上下文大小最大的Transformer之一，克服了視覺-語言訓練的挑戰，並開源了能夠處理超過100萬標記的多模態序列的優化模型。這項工作使得在大規模數據集上進行訓練成為可能，以發展對人類知識和多模態世界的理解，為更廣泛的AI能力鋪平了道路。                                                     | 多模態LLM                      |
| 2024年2月10日 | [ChemLLM: A Chemical Large Language Model](https://arxiv.org/pdf/2402.06852.pdf)                                                                                                                                                                                                                           | 這篇論文介紹了ChemLLM，首個專門為化學應用設計的大型語言模型，旨在解決將結構化化學數據整合到連貫對話中的挑戰。通過模板化指令構建方法，ChemLLM將結構化知識轉化為普通對話，以有效地進行語言模型訓練。ChemLLM在名稱轉換、分子描述和反應預測等關鍵化學任務上表現超越了GPT-3.5和GPT-4，展示了其在相關數學和物理任務上的卓越適應性。此外，ChemLLM在化學領域內的專業NLP任務上表現出色，開啟了化學研究的新探索途徑。                                                                | 特定任務的LLM                  |
| 2024年2月6日  | [LLM Agents can Autonomously Hack Websites](https://arxiv.org/pdf/2402.06664v1.pdf)                                                                                                                                                                                                                      | 這篇論文展示了LLM，特別是GPT-4，具備自主進行網站黑客任務的能力，例如盲數據庫模式提取和SQL注入，而無需事先了解漏洞。這種能力由於先進模型擅長工具使用和利用擴展上下文而實現，這引發了對LLM代理潛在攻擊能力的擔憂，並促使人們對其在網絡安全環境中的廣泛部署提出疑問。                                                                                                                                                                                                                                                                                                                                                                        | LLM代理                        |
| 2024年2月6日  | [AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls](https://arxiv.org/pdf/2402.04253.pdf)                                                                                                                                                                                            | 這篇論文介紹了AnyTool，一個設計用於提高來自Rapid API的超過16,000個API使用效率的大型語言模型代理。AnyTool包括一個API檢索器、一個查詢解析求解器和一個自我反思機制。由GPT-4的函數調用功能驅動，AnyTool消除了外部模組訓練的需求。此外，該論文修訂了評估協議，介紹了AnyToolBench，展示了其在各種數據集上的優異性能，超過了ToolLLM和一個專為工具使用調整的GPT-4變體。代碼可在[https://github.com/dyabel/AnyTool](https://github.com/dyabel/AnyTool)獲得。                                                                  | LLM代理                        |
| 2024年2月6日  | [Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning](https://arxiv.org/pdf/2402.03667.pdf)                                                                                                                                                          | 這篇論文提出了一種新穎的間接推理（IR）方法，以超越連鎖思維和自我一致性等直接推理（DR）框架的限制，增強LLM的推理能力。通過利用反證法和矛盾的邏輯，IR方法解決了事實推理和數學證明等任務。在GPT-3.5-turbo和Gemini-pro等流行LLM上的實驗結果表明，與傳統DR方法相比，IR方法在事實推理和數學證明方面顯著提高了準確性。將IR與DR結合進一步提升了性能，突顯了該策略的有效性。                                                                                                             | 提示工程                       |
| 2024年2月6日  | [Self-Discover: Large Language Models Self-Compose Reasoning Structures](https://arxiv.org/pdf/2402.03620.pdf)                                                                                                                                                                                             | 這篇論文介紹了SELF-DISCOVER，一個框架，使LLM能夠自主識別特定任務的推理結構，從而在BigBench-Hard和MATH等挑戰性推理基準上提高性能。通過在自我發現過程中選擇和組合原子推理模塊，SELF-DISCOVER增強了推理能力，與傳統方法（如連鎖思維）相比，表現出色，最高可提升32%。值得注意的是，SELF-DISCOVER比自我一致性等推理密集的方法高出20%以上的性能，且推理計算需求顯著降低，同時在不同LLM模型家族中表現出普遍性，與人類推理模式相呼應。                                                                             | 提示工程                       |
| 2024年2月6日  | [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300.pdf)                                                                                                                                                                                 | 這篇論文介紹了DeepSeekMath 7B，一個旨在通過繼續預訓練大數據集來應對數學推理挑戰的模型，數據來源於Common Crawl。在不使用外部工具包的情況下，在MATH基準上取得了51.7%的顯著成績，接近Gemini-Ultra和GPT-4等先進模型的性能。DeepSeekMath的成功歸功於利用Sophisticated Data Selection Pipeline來選擇網頁數據，並使用Group Relative Policy Optimization（GRPO）來增強數學推理，同時優化內存使用。                                                                                                                                                                                                                         | 特定任務的LLM                  |
| 2024年2月4日  | [Large Language Model for Table Processing: A Survey](https://arxiv.org/pdf/2402.05121.pdf)                                                                                                                                                                                                               | 這項調查提供了一個關於表格中心任務和LLM自動化的全面概述，包括傳統領域（如表格QA和事實驗證）以及新興方面（如表格操作和高級數據分析）。它深入探討了LLM使用的最新範式，重點關注指令調整、提示和基於代理的方法。該論文還討論了私有部署、高效推理以及表格操作和高級數據分析中需要大量基準的挑戰。                                                                                                                                                                                                                                                                                                                                                                       | 特定任務的LLM                  |
| 2024年2月3日  | [More Agents Is All You Need](https://arxiv.org/pdf/2402.05120.pdf)                                                                                                                                                                                                                                       | 這篇論文展示了通過使用簡單的抽樣和投票方法擴展實例化代理數量可以提高LLM的性能。這種方法獨立於現有的複雜增強技術，其有效性與任務難度相關。跨各種LLM基準的大量實驗驗證了這一發現，並探索了相關性質。實驗代碼在Git上公開。                                                                                                                                                                                                                                                                                                                                       | LLM代理                        |
| 2024年2月1日  | [OLMo: Accelerating the Science of Language Models](https://arxiv.org/pdf/2402.00838.pdf)                                                                                                                                                                                                                 | OLMo旨在通過提供一個快速實驗和理解LLM的平台來加速語言模型科學的發展。它提供了模型訓練、微調和評估的工具，以及一個為研究人員提供的協作環境。目標是促進LLM技術的發現和進步，使其更易於廣大受眾。                                                                                                                                                                                                                                                                                                                                                                                                                    | 開源LLM                        |

