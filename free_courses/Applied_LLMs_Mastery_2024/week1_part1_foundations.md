# [Week 1, Part 1] 應用LLM基礎和真實世界使用案例

[2024年1月15日] 你可以在[這裡](https://forms.gle/353sQMRvS951jDYu7)註冊以接收課程內容和其他資源。

## ETMI5: 用五分鐘解釋給我聽

在本課程的這部分，我們深入探討大型語言模型（LLMs）的複雜性。我們首先探索人工智慧（AI）、機器學習（ML）、神經網絡（NNs）和生成式AI（GenAI）的歷史背景和基本概念。接著，我們檢視LLMs的核心屬性，重點在於它們的規模、在多樣化數據集上的廣泛訓練，以及模型參數的角色。然後，我們討論使用LLMs相關的挑戰類型。

在下一節中，我們將探討LLM在各個領域中的實際應用，強調其在內容生成、語言翻譯、文本摘要、問題解答等方面的多功能性。該節最後分析了部署LLM時遇到的挑戰，涵蓋了延展性、延遲、監控等重要方面。

總結來說，本課程的這部分提供了對大型語言模型的實用且資訊豐富的探索，提供了對其演變、功能、應用、挑戰和實際影響的見解。

## 歷史和背景

![歷史](img/history.png)

圖片來源: [https://medium.com/womenintechnology/ai-c3412c5aa0ac](https://medium.com/womenintechnology/ai-c3412c5aa0ac)。

上述圖片中提到的術語可能在有關 ChatGPT 的對話中出現過。該視覺表示提供了一個廣泛的概述，展示了它們如何適應層次結構。AI 是一個全面的領域，其中 LLMs 構成了一個特定的子領域，而 ChatGPT 在此上下文中則是 LLM 的一個例子。

總結來說，**人工智慧（AI）**是電腦科學的一個分支，涉及創建具有類似人類思維和行為的機器。**機器學習（ML）**是AI的一個子領域，允許電腦從資料中學習模式並在沒有明確編程的情況下進行預測。**神經網絡（NNs）**是ML的一個子集，模仿人腦的結構，並在深度學習算法中至關重要。深度學習（DL）是NN的一個子集，對於複雜問題的解決非常有效，如圖像識別和語言翻譯技術中所見。**生成式AI（GenAI）**是DL的一個子集，能夠基於學習的模式創建多樣化的內容。**大型語言模型（LLMs）**是GenAI的一種形式，專門通過學習大量文本資料來生成類似人類的文本。

生成式 AI 和大型語言模型 (LLMs) 已經徹底改變了人工智慧領域，使機器能夠創建多樣化的內容，如文字、圖像、音樂、音頻和影片。與分類的判別模型不同，生成式 AI 模型通過學習人類創建的數據集中的模式和關係來生成新內容。

在生成式 AI 的核心是基礎模型，這些模型本質上是能夠多工的大型 AI 模型，可以直接執行摘要、問答和分類等任務。這些模型，如大家都聽說過的熱門模型-ChatGPT，可以通過最少的訓練適應特定的使用案例，並使用最少的範例數據生成內容。

生成式 AI 的訓練通常涉及監督學習，模型會被提供人類創建的內容和相應的標籤。通過學習這些資料，模型能夠熟練地生成類似於訓練集的內容。

生成式 AI 不是一個新概念。一個早期生成式 AI 的顯著範例是馬可夫鏈，這是一個由俄羅斯數學家安德烈·馬可夫在 1906 年引入的統計模型。馬可夫模型最初用於像下一個單詞預測這樣的任務，但它們的簡單性限制了它們生成合理文本的能力。

隨著更強大的架構和更大的數據集的出現，這些年來景觀發生了顯著變化。2014年，生成對抗網絡（GANs）出現，使用兩個模型一起工作——一個生成輸出，另一個區分真實數據和生成的輸出。這種方法，以StyleGAN等模型為例，顯著提高了生成內容的真實感。

一年後，引入了擴散模型，通過迭代地改進其輸出來生成類似於訓練數據集的新數據樣本。這一創新，如在Stable Diffusion中所見，有助於創建逼真的圖像。

2017年，Google 推出了 transformer 架構，這是自然語言處理的一大突破。Transformers 將每個詞編碼為一個 token，生成一個注意力圖，捕捉 token 之間的關係。這種對上下文的注意力增強了模型生成連貫文本的能力，以大型語言模型如 ChatGPT 為例。

生成式 AI 的熱潮不僅歸功於更大的數據集，還有多樣的研究進展。這些方法，包括 GANs、擴散模型和 transformers，展示了為生成式 AI 這一令人興奮的領域做出貢獻的方法的廣度。

## 進入 LLMs

"大型"語言模型（LLMs）中的"大型"一詞是指這些模型的規模——無論是在其架構的大小還是它們所訓練的龐大數據量方面。規模之所以重要，是因為它允許它們捕捉語言中更複雜的模式和關係。像 GPT-3、Gemini、Claude 等流行的 LLMs 擁有數千億的模型參數。在機器學習的背景下，模型參數就像是算法在訓練過程中調整的旋鈕和開關，以做出準確的預測或生成有意義的輸出。

現在，讓我們分解「語言模型」在此上下文中的含義。語言模型本質上是被訓練來理解和生成類似人類文本的算法或系統。它們作為語言運作方式的表徵，從多樣化的數據集中學習，以預測在給定上下文中接下來可能出現的單詞或單詞序列。

"大型"這一面向放大了它們的能力。傳統的語言模型，尤其是過去的那些，規模較小，無法有效捕捉語言的複雜性。隨著技術的進步和大量計算能力的可用性，我們已經能夠建構更大的模型。這些大型語言模型，如ChatGPT，擁有數十億個參數，這些參數本質上是模型用來理解語言的變數。

請查看下面來自「Information is beautiful」的資訊圖表，以了解最近的 LLMs 有多少參數。你可以在[此處](https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/)查看即時視覺化。

![llm_sizes.png](img/llm_sizes.png)

圖片來源: [https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/](https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/)

## 訓練LLM

訓練 LLMs 是一個複雜的過程，涉及指導模型理解和生成類似人類的文本。以下是 LLM 訓練如何運作的簡化說明：

1. **提供輸入文本:**
    - LLMs 最初會接觸到大量的文本數據，包括各種來源如書籍、文章和網站。
    - 模型在訓練期間的任務是根據提供的上下文來預測序列中的下一個單詞或標記。它學習文本數據中的模式和關係。
2. **優化模型權重:**
    - 模型包含與其參數相關的不同權重，反映各種特徵的重要性。
    - 在整個訓練過程中，這些權重會被微調以最小化錯誤率。目標是提高模型在預測下一個單詞時的準確性。
3. **微調參數值:**
    - LLMs 根據預測期間收到的錯誤反饋不斷調整參數值。
    - 模型通過反覆調整參數來改進其對語言的理解，提高預測後續標記的準確性。

訓練過程可能會因為正在開發的特定類型LLM而有所不同，例如那些針對連續文本或對話進行最佳化的LLM。

LLM 表現受到兩個關鍵因素的嚴重影響:

- **模型架構:** LLM架構的設計和複雜性影響其捕捉語言細微差別的能力。
- **數據集:** 用於訓練的數據集的品質和多樣性對塑造模型的語言理解至關重要。

訓練一個私有的 LLM 需要大量的計算資源和專業知識。過程的持續時間可以從幾天到幾週不等，取決於模型的複雜性和資料集的大小。通常，基於雲端的解決方案和高效能的 GPU 被用來加速訓練過程，使其更有效率。總的來說，LLM 訓練是一個細緻且資源密集的工作，為模型的語言理解和生成能力奠定了基礎。

在初始訓練之後，可以使用相對較小的監督資料集輕鬆地為各種任務自訂 LLMs，這個過程稱為微調。

有三種流行的學習模型:

1. **零樣本學習:** 基礎LLM可以處理各種請求而無需明確訓練，通常通過使用提示，儘管回應的準確性可能會有所不同。
2. **少樣本學習:** 通過提供少量相關的訓練範例，基礎模型在特定領域的性能顯著提高。
3. **領域適應:** 這是少樣本學習的延伸，實踐者使用與特定應用或領域相關的額外數據訓練基礎模型以調整其參數。

我們將在課程中深入探討這些方法。

## LLM 真實世界使用案例

LLM 已經在各種應用中展示其多樣性和這些模型在改變多個領域中的強大力量。以下是 LLM 如何應用於特定案例:

![藍色和灰色的創意心智圖.png](img/Blue_and_Grey_Illustrative_Creative_Mind_Map.png)

1. **內容產生:**
    - LLMs 在內容產生方面表現出色，能夠理解上下文並生成連貫且與上下文相關的文本。它們可以用於自動生成創意內容，如行銷、社交媒體貼文和其他溝通材料，確保高水準的品質和相關性。
    - **實際應用:** 行銷平台、社交媒體管理工具、內容創作平台、廣告代理商
2. **語言翻譯:**
    - LLMs 可以通過理解不同語言的細微差別顯著改善語言翻譯任務。它們可以提供準確且上下文感知的翻譯，使其成為在多語環境中運營的企業的寶貴工具。這可以增強全球溝通和拓展。
    - **實際應用:** 翻譯服務、全球溝通平台、國際商務應用
3. **文本摘要:**
    - LLMs 擅長通過識別關鍵資訊並保持核心信息來總結冗長的文件。這一能力對於內容創作者、研究人員和希望快速從大量文本中提取重要見解的企業來說非常有價值，提高了資訊消費的效率。
    - **實際應用:** 研究工具、新聞聚合器、內容策展平台
4. **問題回答和聊天機器人:**
    - LLMs 可以用於問題回答任務，理解問題的上下文並生成相關且準確的回應。它們使這些系統能夠進行更自然且上下文感知的對話，理解用戶查詢並提供相關回應。
    - **實際應用:** 客戶支持系統、聊天機器人、虛擬助手、教育平台
5. **內容審核:**
    - LLMs 可以通過分析文本並識別潛在的不當或有害內容來用於內容審核。這有助於通過自動標記或過濾違反指南的內容來維護安全和尊重的在線環境，確保用戶安全。
    - **實際應用:** 社交媒體平台、在線論壇、社區管理工具
6. **資訊檢索:**
    - LLMs 可以通過理解用戶查詢並從大型數據集中檢索相關資訊來增強資訊檢索系統。這在搜索引擎、數據庫和知識管理系統中特別有用，LLMs 可以提高搜索結果的準確性。
    - **實際應用:** 搜索引擎、數據庫系統、知識管理平台
7. **教育工具:**
    - LLMs 通過為學習平台提供自然語言界面來促進教育工具。它們可以幫助學生生成摘要、回答問題並參與互動學習對話。這有助於個性化和高效的學習體驗。
    - **實際應用:** 電子學習平台、教育聊天機器人、互動學習應用

熱門 LLM 使用案例總結

| No. | Use case | Description |
| --- | --- | --- |
| 1 | Content Generation | 根據指示創作類似人類的文本、影片、程式碼和圖像 |
| 2 | Language Translation | 將語言從一種翻譯成另一種 |
| 3 | Text Summarization | 摘要冗長的文本，通過突出重點來簡化理解。 |
| 4 | Question Answering and Chatbots | LLMs 可以利用其廣泛的知識提供相關的答案 |
| 5 | Content Moderation | 協助內容審核，識別和過濾不當或有害的語言 |
| 6 | Information Retrieval | 從大型數據集或文件中檢索相關資訊。 |
| 7 | Educational Tools | 教導、提供解釋和生成學習材料。 |

了解生成式 AI 模型的利用，特別是 LLMs，也可以從在這個領域運作的大量初創公司中獲得啟示。Sequoia Capital 提供的[資訊圖表](https://www.sequoiacap.com/article/generative-ai-act-two/)突顯了這些公司在不同領域的分佈，展示了多樣化的應用以及在生成式 AI 領域中眾多玩家的重要存在。

![business_cases.png](img/business_cases.png)

圖片來源: [https://markovate.com/blog/applications-and-use-cases-of-llm/](https://markovate.com/blog/applications-and-use-cases-of-llm/)

## LLM 挑戰

![llm_challenges.png](img/llm_challenges.png)

雖然 LLMs 無疑已經革新了各種應用，但仍然存在許多挑戰。這些挑戰被分類為不同的主題:

- **資料挑戰:** 這與訓練所使用的資料有關，以及模型如何解決資料中的缺口或遺漏。
- **倫理挑戰:** 涉及解決如減少偏見、確保隱私以及防止在部署LLM時生成有害內容等問題。
- **技術挑戰:** 這些挑戰集中在LLM的實際實施上。
- **部署挑戰:** 關注將完全功能的LLM轉換為實際使用案例（生產化）所涉及的具體過程。

**資料挑戰:**

1. **資料偏見:** 訓練資料中的偏見和不平衡導致模型輸出結果有偏見。
2. **有限的世界知識和幻覺:** LLMs 可能缺乏對現實世界事件和資訊的全面理解，並且傾向於幻覺資訊。請注意，訓練它們使用新資料是一個漫長且昂貴的過程。
3. **依賴訓練資料品質:** LLM 的性能受到訓練資料品質和代表性的強烈影響。

**倫理和社會挑戰:**

1. **倫理問題:** 關於語言模型在敏感情境中負責任和倫理使用的問題。
2. **偏見放大:** 訓練數據中存在的偏見可能會被放大，導致不公平或歧視性的輸出。
3. **法律和版權問題:** 由於生成的內容侵犯版權或違反法律而可能引發的法律問題。
4. **用戶隱私問題:** 基於用戶輸入生成文本時的風險，特別是在處理私人或敏感資訊時。

**技術挑戰:**

1. **計算資源:** 訓練和部署大型語言模型需要大量的計算能力。
2. **可解釋性:** 理解和解釋複雜模型的決策過程存在挑戰。
3. **評估:** 評估是一個顯著的挑戰，因為在不同任務和領域中評估模型的設計不足，特別是由於自由生成內容帶來的挑戰。
4. **微調挑戰:** 適應預訓練模型到特定任務或領域的困難。
5. **上下文理解:** 大型語言模型在較長段落或對話中保持連貫上下文方面可能面臨挑戰。
6. **對抗攻擊的魯棒性:** 對故意操縱輸入數據導致錯誤輸出的脆弱性。
7. **長期上下文:** 在長篇文本或討論中保持上下文和連貫性的困難。

**部署挑戰:**

1. **延展性:** 確保模型能有效延展以處理生產環境中增加的工作負載和需求。
2. **延遲:** 最小化模型的回應時間或延遲，以提供快速且有效的互動，特別是在即時應用中。
3. **監控和維護:** 實施強大的監控系統以追蹤模型性能、檢測問題並進行定期維護以避免停機。
4. **與現有系統的整合:** 確保LLM與組織內現有軟體、資料庫和基礎設施的順利整合。
5. **成本管理:** 優化部署和維護大型語言模型的成本，因為它們在計算和存儲方面可能資源密集。
6. **安全問題:** 解決在生產中部署語言模型相關的潛在安全漏洞和風險，包括防範惡意攻擊。
7. **互操作性:** 確保與其他工具、框架或系統的相容性，這些可能是整體生產管道的一部分。
8. **用戶反饋納入:** 開發機制以納入用戶反饋，持續改進並更新生產環境中的模型。
9. **法規遵從:** 遵守法規要求和合規標準，特別是在具有嚴格數據保護和隱私法規的行業中。
10. **動態內容處理:** 管理在內容和用戶互動頻繁變化的動態環境中生成的文本。

## 閱讀/觀看這些資源 (選擇性)

1. [https://www.nvidia.com/en-us/glossary/generative-ai/](https://www.nvidia.com/en-us/glossary/generative-ai/)
2. [https://markovate.com/blog/applications-and-use-cases-of-llm/](https://markovate.com/blog/applications-and-use-cases-of-llm/)
3. [https://www.sequoiacap.com/article/generative-ai-act-two/](https://www.sequoiacap.com/article/generative-ai-act-two/)
4. [https://datasciencedojo.com/blog/challenges-of-large-language-models/](https://datasciencedojo.com/blog/challenges-of-large-language-models/)
5. [https://snorkel.ai/enterprise-llm-challenges-and-how-to-overcome-them/](https://snorkel.ai/enterprise-llm-challenges-and-how-to-overcome-them/)
6. [https://www.youtube.com/watch?v=MyFrMFab6bo](https://www.youtube.com/watch?v=MyFrMFab6bo)
7. [https://www.youtube.com/watch?v=cEyHsMzbZBs](https://www.youtube.com/watch?v=cEyHsMzbZBs)

## 閱讀這些論文（可選）

1. [https://dl.acm.org/doi/abs/10.1145/3605943](https://dl.acm.org/doi/abs/10.1145/3605943)
2. [https://www.sciencedirect.com/science/article/pii/S2950162823000176](https://www.sciencedirect.com/science/article/pii/S2950162823000176)
3. [https://arxiv.org/pdf/2303.13379.pdf](https://arxiv.org/pdf/2303.13379.pdf)
4. [https://proceedings.mlr.press/v202/kandpal23a/kandpal23a.pdf](https://proceedings.mlr.press/v202/kandpal23a/kandpal23a.pdf)
5. [https://link.springer.com/article/10.1007/s12599-023-00795-x](https://link.springer.com/article/10.1007/s12599-023-00795-x)

