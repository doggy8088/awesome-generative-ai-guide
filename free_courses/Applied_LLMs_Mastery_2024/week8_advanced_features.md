# [第8週] 高級功能和部署

## ETMI5: 用五分鐘解釋給我聽

在我們的內容的這一部分，我們將深入探討部署 LLMs 的複雜性並在其生命週期中有效地管理它們。我們將首先討論 LLMOps，這涉及專門針對在生產環境中運營管理 LLMs 的實踐、技術和工具。我們將探索 LLMs 的部署生命週期，檢查運營效率重要的領域。然後我們將深入討論部署的關鍵組成部分，即 LLMs 的監控和可觀察性，以及 LLMs 的安全性和合規性。

## LLM 應用階段

在部署 LLMs 時，建立一個抽象層來有效管理其周圍的任務是至關重要的，以確保順利運行和最佳性能。這一層通常被稱為 LLMOps，下面給出了一個更正式的定義:

LLMOps，或大型語言模型操作，指的是在生產環境中用於操作管理大型語言模型的專業實踐、技術和工具。這個領域專注於管理和自動化大型語言模型的生命周期，從開發、部署到維護，確保這些模型的高效部署、監控和維護。

在接下來的部分中，我們將首先探討 LLMs 的部署生命週期，然後檢視運營效率至關重要的關鍵領域。

以下是遵循 LLM 生命週期時間順序的大綱:

### **1. 開發前期和規劃**

這個階段通過強調與更廣泛的 AI 和 ML 社區的早期互動，並將道德考量納入模型開發策略，為成功的 LLM 專案奠定基礎。它涉及了解 LLM 技術的全貌，包括趨勢、機會和挑戰，以及預先處理潛在的道德和偏見問題。這個階段對於使專案與最佳實踐、法律和道德標準保持一致至關重要，並確保開發團隊具備最新的知識和工具。它包括以下組成部分:

- **文獻調查**: 早期與 AI 和 ML 社群互動，以了解當前趨勢、挑戰和最佳實踐。
- **倫理模型開發**: 在規劃階段考慮倫理影響、潛在偏見和隱私問題，以指導開發過程。

### **2. 資料準備和分析**

數據是LLM的核心，這個超類別專注於數據的收集、清理、標記和準備，隨後進行探索性分析以了解其特徵並為後續的建模決策提供資訊。這個階段對於確保數據的高品質、代表性和盡可能無偏見至關重要，為訓練有效且可靠的模型奠定了堅實的基礎。這個階段可以分為：

- **資料管理**: 初始步驟包括收集、清理、標記和準備資料，這是訓練 LLMs 的基礎。
- **探索性資料分析**: 分析資料以了解其特性，這會影響模型訓練策略和提示設計。

### **3. 模型開發和訓練**

在這個階段，重點轉向 LLM 的實際建構和最佳化，涉及在準備好的資料上進行訓練和微調，以及提示工程以引導模型生成所需的輸出。這個階段是模型執行特定任務的能力被開發和改進的時期，使其成為設定模型最終性能和適用於現實世界任務的關鍵時期。這個階段可以分為:

- **模型訓練和微調**: 利用預訓練模型並使用特定數據集進行調整，以提升針對性任務的表現。
- **提示工程**: 開發引導模型生成所需輸出的輸入，這對於有效的模型訓練和任務表現至關重要。

### **4. 最佳化 for Deployment**

在部署之前，模型會經過超參數調整、修剪和量化等最佳化過程，以平衡性能和計算效率。這個超類別是關於確保模型高效運行、可以部署在所需平台上並達到必要的性能基準，從而使模型準備好應用於現實世界。這個階段可以分為：

- **超參數調整**: 微調模型參數以平衡性能和計算效率，在部署前至關重要。
- **模型修剪和量化**: 使用的技術使模型更輕更快，特別是在資源受限的環境中，便於部署。

### **5. 部署和整合**

這個階段涉及使訓練和最佳化的模型可供實際應用，通常通過 API 或網路服務，並將其整合到現有系統或工作流程中。它包括自動化部署過程，以促進順利的更新和延展性。這個階段是將模型的能力轉化為實用的工具或服務的關鍵。它可以分為:

- **部署過程**: 通過適當的介面（如 API 或網路服務）使模型可用於生產環境。
- **持續整合與交付（CI/CD）**: 自動化模型開發、測試和部署過程，以確保從開發到生產的順利過渡。

### **6. 部署後監控和維護**

部署後，持續監控和維護對於確保模型隨時間推移持續表現良好、保持安全並遵守合規要求至關重要。這包括追蹤性能、識別和糾正漂移或退化，以及根據需要更新模型。這個階段確保了 LLM 在生產環境中的長期可靠性和有效性。它可以分為：

- **監控和可觀察性**: 持續追蹤模型的表現，以檢測和解決模型漂移等問題。
- **模型審查和治理**: 管理模型的生命周期，包括更新、版本控制，並確保它們符合性能基準。
- **安全和合規**: 確保持續遵守法律和道德標準，包括資料隱私和安全協議。

### **7. 持續改進與合規**

這個總體類別強調了定期重新檢視和改進模型及其部署策略的重要性，以適應新的資料、反饋和不斷變化的監管環境。它強調了主動、迭代的方法來管理 LLMs，確保它們保持最先進、合規，並符合用戶需求和道德標準。它可以分為

- **隱私和法規遵循**: 定期審查和更新做法以遵守不斷變化的法規，如GDPR和CCPA。
- **最佳實踐採用**: 實施最新的方法和工具，用於數據科學和軟體工程，以改進和增強模型開發和部署過程。

現在我們了解了部署和管理 LLMs 的必要步驟，讓我們進一步探討對部署更具相關性的方面，即在本課程的這一部分，回顧部署後的過程，建立在過去幾週討論的基礎上。

雖然階段1-5已經先前概述過，且某些元素如資料準備和模型開發在所有機器學習模型中都是通用的，我們現在的重點轉向專注於部署LLM時涉及的細微差別。

我們將更詳細地探討以下領域:

- **大型語言模型的部署**: 了解部署大型語言模型的複雜性以及促進持續學習和適應的機制。
- **大型語言模型的監控和可觀察性**: 探討保持大型語言模型性能警惕和確保運營透明度的策略和技術。
- **大型語言模型的安全性和合規性**: 解決保護大型語言模型免受威脅並確保遵守倫理標準和實踐的方法。

## **部署LLMs**

將 LLM 部署到生產環境中需要對技術環境和應用程式的具體需求有良好的理解。以下是在部署 LLM 應用程式時需要記住的一些關鍵考量:

### **1. Choice Between External Providers and Self-hosting**

- **外部提供者**: 利用像 OpenAI 或 Anthropic 這樣的服務可以通過外包計算任務來簡化部署，但可能涉及更高的成本和數據隱私問題。
- **自行託管**: 選擇開放原始碼模型提供了對數據和成本的更大控制，但需要在設定和管理基礎設施方面投入更多努力。

### **2. 系統設計和延展性**

- 一個穩健的 LLM 應用服務必須確保無縫的用戶體驗和全天候可用性，這需要容錯、零停機升級和高效的負載平衡。
- 延展性必須進行規劃，考慮當前需求和潛在增長，以便在處理不同負載時不會降低性能。

### **3. 監控和可觀察性**

- **效能指標**: 如每秒查詢數(QPS)、延遲和每秒標記數(TPS)，對於了解系統的效率和容量至關重要。
- **品質指標**: 根據應用的使用情境定制，這些指標有助於評估LLM的輸出品質和相關性。

我們將在下一節更深入地探討這一點。

### **4. 成本管理**

- 部署 LLMs，特別是在大規模時，可能會很昂貴。成本管理策略包括謹慎的資源分配、利用成本效益高的計算資源（例如，spot instances），以及通過請求批次處理等技術來最佳化模型推論成本。

### **5. 資料隱私和安全**

- 確保資料隱私和遵守法規（例如 GDPR）是最重要的，特別是在使用 LLMs 處理敏感資訊時。
- 應採取安全措施來保護正在處理的資料和應用程式本身免受未經授權的訪問和攻擊。

### **6. 快速迭代和靈活性**

- 由於該領域的快速發展，快速迭代和調整 LLM 應用程式的能力至關重要。基礎設施應支持快速部署、測試和回滾程序。
- 部署策略的靈活性允許根據性能反饋、新興最佳實踐和不斷變化的業務需求進行調整。

### **7. 基礎設施即程式碼 (IaC)**

- 使用 IaC 來定義和管理基礎設施可以大大提高部署過程的可重現性、一致性和速度，從而更容易擴展和管理 LLM 應用程式。

### **8. 模型組合和任務可組合性**

- 許多應用程式需要組合多個模型或任務，因此需要一個能有效支援這些組合的系統設計。
- 有助於整合和協調不同 LLM 元件的工具和框架對於建構複雜應用程式至關重要。

### **9. 硬體和資源最佳化**

- 根據應用程式的延遲和吞吐量需求選擇合適的硬體（GPUs, TPUs）對於性能最佳化至關重要。
- 有效的資源管理策略，如自動擴展和負載平衡，確保計算資源被有效利用，平衡成本和性能。

### **10. 法律和道德考量**

- 除了技術和操作考量之外，部署LLM還涉及到模型影響、潛在偏見和輸出公平性的倫理考量。
- 必須仔細審查和遵守有關AI和數據使用的法律義務，確保LLM的部署符合社會規範和法規。

## **監控和可觀測性對於 LLMs**

監控和可觀察性指的是在部署和運行過程中，用於追踪、分析和理解這些模型行為和性能的過程和工具。

監控對於 LLMs 至關重要，以確保最佳性能、檢測故障、規劃容量、維護安全和合規性、管理模型並推動持續改進。

以下是一些應該監控的 LLMs 關鍵指標，我們已經在課程的前幾部分討論過監控工具

### 基本監控策略

**1. 使用者面向的效能指標**

- **延遲**: LLM 回應查詢所需的時間，對用戶滿意度至關重要。
- **可用性**: LLM 服務運行並可供用戶訪問的時間百分比，反映其可靠性。
- **錯誤率**: 不成功請求或回應的頻率，表明 LLM 或其整合點可能存在問題。

**2. 模型輸出**

- **準確性**: 衡量 LLM 提供正確或有用回應的頻率，這是其價值的基礎。
- **信心分數**: LLM 對其回應準確性的自我評估，有助於篩選或優先處理輸出。
- **彙總指標**: 編輯性能指標，如精確度、召回率和 F1 分數，以評估整體模型效能。

**3. 資料輸入**

- **記錄查詢**: 記錄使用者輸入到LLM的資訊，以便稍後分析、故障排除和了解使用者互動模式。
- **可追溯性**: 確保從輸入到輸出的清晰路徑，有助於除錯和改進模型回應。

**4. 資源利用**

- **計算使用量**: 追蹤 CPU/GPU 消耗以優化計算資源分配和成本。
- **記憶體使用量**: 監控 LLM 使用的記憶體量，這對於管理大型模型和防止系統過載非常重要。

**5. 訓練資料漂移**

- **統計分析**: 使用統計測試來比較當前輸入數據分佈與訓練數據集的分佈，識別顯著差異。
- **檢測機制**: 實施自動化系統以警示檢測到的漂移，確保LLM隨時間保持準確。

**6. 自訂度量**

- **應用程式特定的KPI**: 開發與應用程式目標直接相關的獨特指標，例如用戶參與度或內容生成品質。
- **創新追蹤**: 不斷演變的指標，以捕捉新的見解並改善LLM性能和用戶體驗。

### 進階監控策略

**1. 即時監控**

- **即時見解**: 提供對LLM運作的即時檢視，能夠快速檢測和回應問題。
- **系統效能**: 了解LLM在各種條件下的動態行為，實時調整資源。

**2. 資料漂移偵測**

- **維持模型準確性**: 定期將輸入資料與模型的訓練資料進行比較，以確保一致性和相關性。
- **自適應策略**: 實施機制以調整模型或其輸入，以應對檢測到的漂移，保持效能。

**3. 延展性和效能**

- **需求管理**: 設計LLM系統以擴展資源以應對用戶需求，確保響應速度。
- **效率最佳化**: 微調部署架構以達到最佳性能，平衡速度與成本。

**4. 可解釋性與除錯**

- **模型理解**: 應用特徵重要性、注意力機制和基於範例的解釋等技術來解讀模型決策。
- **除錯工具**: 利用日誌、度量和模型內部資訊來診斷和解決問題，增強模型可靠性。

**5. 偏見檢測與公平性**

- **主動偏見監控**: 定期評估模型輸出中的無意偏見，確保對不同用戶群體的公平回應。
- **公平性指標**: 開發和追踪公平性指標，通過模型調整或重新訓練來糾正偏見。

**6. 合規實踐**

- **法規遵循**: 確保LLM符合法律和道德標準，包含資料保護、隱私和透明度措施。
- **審計和報告**: 維護LLM操作、決策和調整的記錄，以符合法規要求並促進審計。

## **LLM 的安全性和合規性**

### 安全性

在 LLM 部署中維護安全性至關重要，因為這些模型在文本生成、問題解決和解釋複雜指令方面具有先進的能力。隨著 LLM 越來越多地與外部工具、API 和應用程式整合，它們為惡意行為者的潛在濫用開闢了新的途徑，引發了對社交工程、資料外洩和敏感資訊安全處理的擔憂。為了防範這些風險，企業必須制定全面的策略來規範 LLM 的輸出並減輕安全漏洞。

安全在防止其被濫用來生成誤導性內容或促進惡意活動（如社交工程攻擊）方面起著至關重要的作用。通過實施強大的安全措施，組織可以保護LLM處理的敏感資料，確保機密性和隱私。此外，保持嚴格的安全實踐有助於維護用戶信任，並確保遵守法律和道德標準，促進LLM技術的負責任部署和使用。本質上，優先考慮LLM的安全性對於保護模型的完整性和與之互動的用戶信任至關重要。

**如何確保 LLM 安全性？**

- **資料安全**: 實施來自人類反饋的強化學習（RLHF）和外部審查機制，以使LLM輸出符合人類價值觀並過濾掉不允許的內容。
- **模型安全**: 通過驗證過程、校驗和防止未經授權修改模型架構和參數的措施來保護模型免受篡改。
- **基礎設施安全**: 通過嚴格的安全協議（包括防火牆、入侵檢測系統和加密）來保護託管環境，以防止未經授權的訪問和威脅。
- **倫理考量**: 整合倫理指南，以防止生成有害的、偏見的或誤導性的輸出，確保LLM對用戶和社會做出積極和負責任的貢獻。

### 合規性

LLM 合規性是指遵守其開發、部署和使用的法律、監管和道德標準。它涵蓋了各種方面，如數據隱私法規、知識產權、公平性和偏見緩解、透明度和問責制。

以下是一些需要考慮的事項，以確保在部署 LLMs 時遵守合規標準。

- **熟悉 GDPR 和 EU AI 法案**: 全面了解歐盟的 GDPR 等法規，這些法規管理數據保護和隱私，並隨時更新擬議的 EU AI 法案的進展和要求，特別是關於 AI 系統的部分。
- **國際數據保護法**: 對於全球業務，需了解並遵守其他司法管轄區的數據保護法，確保 LLM 部署符合所有適用的國際標準。

## 閱讀/觀看這些資源 (選擇性)

1. LLM 監控和可觀察性 — 負責任 AI 的技術和方法總結 -[https://towardsdatascience.com/llm-monitoring-and-observability-c28121e75c2f](https://towardsdatascience.com/llm-monitoring-and-observability-c28121e75c2f)
2. LLM 可觀察性- [https://www.tasq.ai/glossary/llm-observability/](https://www.tasq.ai/glossary/llm-observability/)
3. LLMs — 可觀察性和監控**-** [https://medium.com/@bijit211987/llm-observability-and-monitoring-925f93242ccf](https://medium.com/@bijit211987/llm-observability-and-monitoring-925f93242ccf)

