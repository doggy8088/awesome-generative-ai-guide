# [Week 1, Part 2] 領域和任務適應方法

## ETMI5: 用五分鐘解釋給我聽

在本節中，我們深入探討一般 AI 模型在專業領域中的限制，強調適應領域的 LLMs 的重要性。我們探討這些模型的優勢，包括深度、精確度、改進的使用者體驗，以及解決隱私問題。

我們介紹了三種類型的領域適應方法: 領域特定的預訓練、領域特定的微調和檢索增強生成 (RAG)。每種方法都有概述，提供了類型、訓練時間和快速摘要的詳細資訊。然後我們用實際範例進一步解釋了這些方法。最後，我們概述了何時應使用 RAG 而不是模型更新方法。

## 有效使用 LLMs

雖然像 ChatGPT 這樣的一般 AI 模型在各種主題上展示了令人印象深刻的文本生成能力，但它們可能缺乏特定領域所需的深度和細微理解。此外，這些模型更容易生成不準確或上下文不適當的內容，這被稱為幻覺。例如，在醫療保健領域，像「電子健康記錄互操作性」或「以病人為中心的醫療之家」這樣的特定術語具有重要意義，但通用語言模型可能由於缺乏特定的醫療保健數據訓練而難以完全理解其相關性。這就是任務特定和領域特定的 LLM 發揮關鍵作用的地方。這些模型需要具備行業特定術語和實踐的專業知識，以確保準確解釋領域特定的概念。在本課程的其餘部分，我們將這些專業的 LLM 稱為**領域特定 LLM**，這是對此類模型的常用術語。

以下是使用特定領域LLM的一些好處:

1. **深度和精確性**: 一般的 LLMs 雖然能夠生成涵蓋各種主題的文本，但可能缺乏專業領域所需的深度和細微差別。專業領域的 LLMs 針對行業特定術語進行了調整，確保理解的精確性。
2. **克服限制**: 一般的 LLMs 存在一些限制，包括潛在的不準確性、缺乏上下文以及易受幻覺影響。在金融或醫療等需要特定術語的領域，專業領域的 LLMs 在提供準確且上下文相關的資訊方面表現出色。
3. **增強用戶體驗**: 專業領域的 LLMs 通過提供量身定制和個性化的回應來增強用戶體驗。在客戶服務聊天機器人或動態 AI 代理等應用中，這些模型利用專業知識提供更準確和有見地的資訊。
4. **提高效率和生產力**: 企業可以從專業領域的 LLMs 提高的效率中受益。通過自動化任務、生成與行業特定術語一致的內容以及簡化操作，這些模型釋放了人力資源以處理更高層次的任務，最終提升生產力。
5. **解決隱私問題**: 在處理敏感數據的行業中，例如醫療保健，使用一般的 LLMs 可能會帶來隱私挑戰。專業領域的 LLMs 可以提供一個封閉的框架，確保保護機密數據並遵守隱私協議。

如果你還記得[上一節](https://www.notion.so/Week-1-Applied-LLM-Foundations-369ae7cf630d467cbfeedd3b9b3bfc46?pvs=21)，我們有多種方法在特定用例中使用LLM，即

1. **零樣本學習**
2. **少樣本學習**
3. **領域適應**

零樣本學習和少樣本學習涉及通過範例或通過提示特定感興趣的問題來指導通用模型。另一個引入的概念是領域適應，這將是本節的主要重點。關於前兩種方法的更多詳細資訊將在我們深入探討提示主題時進一步探討。

## 領域適應方法的類型

有幾種方法可以將領域特定知識整合到LLM中，每種方法都有其優點和限制。以下是三種類別的方法:

1. **特定領域的預訓練:**
    - ***訓練時間**:* 幾天到幾週到幾個月
    - ***摘要**:* 需要大量的領域訓練數據; 可以自訂模型架構、大小、分詞器等

    在這種方法中，LLM 在代表各種自然語言使用案例的大型數據集上進行預訓練。例如，像 PaLM 540B、GPT-3 和 LLaMA 2 這樣的模型已在大小從 4990 億到 2 兆個標記的數據集上進行了預訓練。特定領域預訓練的範例包括 ESMFold、ProGen2 用於蛋白質序列、Galactica 用於科學、BloombergGPT 用於金融和 StarCoder 用於程式碼。這些模型在其領域內的表現優於通用模型，但在準確性和潛在幻覺方面仍面臨限制。

2. **特定領域的微調:**
    - ***訓練時間**:* 幾分鐘到幾小時
    - ***摘要**:* 添加特定領域數據; 為特定任務進行調整; 更新 LLM 模型

    微調涉及在特定任務或領域上訓練預訓練的 LLM，將其知識適應於更狹窄的上下文。範例包括 Alpaca（微調的 LLaMA-7B 模型用於一般任務）、xFinance（微調的 LLaMA-13B 模型用於金融特定任務）和 ChatDoctor（微調的 LLaMA-7B 模型用於醫療聊天）。與預訓練相比，微調的成本顯著較小。

3. **檢索增強生成 (RAG):**
    - ***訓練時間**:* 不需要
    - ***摘要**:* 沒有模型權重; 外部資訊檢索系統可以調整

    RAG 涉及將 LLM 的參數知識與來自資訊檢索系統的外部或非參數知識結合。這些外部知識作為額外的上下文提供給 LLM 的提示。RAG 的優點包括無訓練成本、低專業知識要求以及能夠引用來源以供人類驗證。這種方法解決了幻覺等限制，並允許精確操控知識。知識庫可以輕鬆更新而不改變 LLM。將非參數知識與 LLM 的參數知識結合的策略正在積極研究。

## **特定領域預訓練**

![domain_specific](img/domain_specific.png)

圖片來源 [https://www.analyticsvidhya.com/blog/2023/08/domain-specific-llms/](https://www.analyticsvidhya.com/blog/2023/08/domain-specific-llms/)。

領域特定的預訓練涉及在廣泛的數據集上訓練大型語言模型，這些數據集專門代表特定領域或領域的語言和特徵。此過程旨在增強模型在定義的主題領域內的理解和性能。讓我們通過[彭博GPT](https://arxiv.org/pdf/2303.17564.pdf)這個金融領域的大型語言模型來了解領域特定的預訓練。

BloombergGPT 是一個擁有 500 億參數的語言模型，旨在在金融行業的各種任務中表現出色。雖然通用模型具有多功能性，並且在各種任務中表現良好，但在專門領域中，它們可能無法超越特定領域的模型。在 Bloomberg，大多數應用都在金融領域，因此需要一個在金融任務中表現出色，同時在一般基準測試中保持競爭力的模型。BloombergGPT 可以執行以下任務:

1. **金融情感分析:** 分析和判斷金融文本中的情感，例如新聞文章、社交媒體帖子或財務報告。這有助於理解市場情緒並做出明智的投資決策。
2. **命名實體識別:** 識別和分類金融文件中提到的實體（如公司、個人和金融工具）。這對於從大型數據集中提取相關資訊至關重要。
3. **新聞分類:** 將金融新聞文章分類為不同的主題或類別。這可以幫助根據其與特定金融領域的相關性來組織和優先處理新聞更新。
4. **金融問答:** 回答與金融主題相關的問題。用戶可以提出關於市場趨勢、金融工具或經濟指標的查詢，BloombergGPT 可以提供相關答案。
5. **金融對話系統:** 進行與金融相關的自然語言對話。用戶可以與 BloombergGPT 互動以尋求資訊、澄清疑問或討論金融概念。

為了達成這一目標，BloombergGPT 使用一個大型數據集進行領域特定的預訓練，該數據集結合了來自 Bloomberg 廣泛檔案的領域特定金融語言文件和公共數據集。這個數據集名為 FinPile，由多樣的英文金融文件組成，包括新聞、申報、新聞稿、網頁抓取的金融文件和社交媒體內容。訓練語料庫大致分為一半領域特定文本和一半通用文本。目的是利用領域特定和一般數據來源的優勢。

模型架構基於先前研究工作的指南，包含70層變壓器解碼器塊（閱讀更多在[論文](https://arxiv.org/pdf/2303.17564.pdf)）。

## **領域專用微調**

特定領域微調是指為特定任務或特定領域精煉現有語言模型，以提升其性能並使其適應該領域的獨特背景。這種方法涉及使用一個已經在包含各種語言使用情況的多樣化數據集上進行過預訓練的LLM，然後在一個與特定領域或任務相關的較窄數據集上進行微調。

💡請注意，前述方法，即領域專屬的預訓練，涉及僅在特定領域的數據上訓練語言模型，從而為該領域創建一個專門的模型。另一方面，領域專屬的微調則是將一個預訓練的通用模型進一步在領域專屬的數據上訓練，使其適應該領域內的任務，而不需要從頭開始。預訓練從一開始就是領域專屬的，而微調則是將一個更通用的模型適應到特定領域。

領域特定微調的關鍵步驟包括:

1. **預訓練:** 最初，一個大型語言模型在廣泛的數據集上進行預訓練，使其能夠掌握一般的語言模式、語法和上下文理解(一個一般的LLM)。
2. **微調數據集:** 收集或準備一個更專注的數據集，針對所需的領域或任務進行定制。這個數據集包含與目標領域相關的範例和實例，可能包括標記範例以進行監督學習。
3. **微調過程:** 預訓練的語言模型在這個特定領域的數據集上進行進一步訓練。在微調過程中，模型的參數根據新的數據集進行調整，同時保留在預訓練期間獲得的一般語言理解。
4. **任務最佳化:** 微調後的模型針對所選領域內的特定任務進行最佳化。這種最佳化可能涉及調整與任務相關的參數，例如模型架構、大小或分詞器，以達到最佳性能。

領域特定的微調提供了幾個優點:

- 它使模型能夠專門針對特定領域，增強其在該領域內任務的有效性。
- 與從頭開始訓練模型相比，它節省了時間和計算資源，利用了預訓練期間獲得的知識。
- 模型可以適應目標領域的具體需求和細微差別，從而提高在特定領域任務上的性能。

一個針對特定領域進行微調的流行範例是 ChatDoctor LLM，它是一個專門的語言模型，使用來自線上醫療諮詢平台的 100,000 個病患-醫生對話數據集，在 Meta-AI 的大型語言模型 meta-AI (LLaMA) 上進行微調。該模型在真實世界的病患互動中進行微調，顯著提高了對病患需求的理解，並提供更準確的醫療建議。ChatDoctor 使用來自線上來源（如 Wikipedia）和精選的離線醫療數據庫的即時資訊，增強其對醫療查詢的回應準確性。該模型的貢獻包括在醫療領域微調 LLMs 的方法論、一個公開共享的數據集，以及一個能夠檢索更新醫學知識的自主 ChatDoctor 模型。閱讀更多關於 ChatDoctor 的論文[此處](https://arxiv.org/pdf/2303.14070.pdf)。

## 檢索增強生成 (RAG)

增強檢索生成（RAG）是一種 AI 框架，通過在生成過程中結合來自外部來源的最新且上下文相關的資訊，提高 LLMs 生成的回應品質。它解決了 LLMs 中的不一致性和缺乏特定領域知識的問題，減少了幻覺或錯誤回應的機會。RAG 包含兩個階段：檢索階段，搜索並檢索相關資訊；內容生成階段，LLM 根據檢索到的資訊及其內部訓練數據綜合生成答案。這種方法提高了準確性，允許來源驗證，並減少了持續模型重新訓練的需求。

![RAG_w1.png](img/RAG_w1.png)

圖片來源: [https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)

上述圖表概述了基本的 RAG 管線，由三個關鍵組成部分構成:

1. **資料攝取:**
    - 文件被分割成塊，並從這些塊生成嵌入，隨後存儲在索引中。
    - 塊對於在回應給定查詢時定位相關資訊至關重要，類似於標準檢索方法。
2. **檢索:**
    - 利用嵌入的索引，系統在接收到查詢時根據嵌入的相似性檢索出前 k 個文件。
3. **綜合:**
    - 檢查塊作為上下文資訊，LLM 利用這些知識來制定準確的回應。

💡與先前的領域適應方法不同，值得強調的是，RAG 完全不需要任何模型訓練。當提供特定領域資料時，它可以直接應用而無需訓練。

與先前的模型更新方法（預訓練和微調）相比，RAG 具有特定的優勢和劣勢。是否使用 RAG 的決定取決於對這些因素的評估。

| RAG 的優點  | RAG 的缺點 |
| --- | --- |
| 資訊新鮮度: RAG 通過提供來自外部資料庫的最新或上下文特定的數據，解決了 LLMs 的靜態特性。 | 複雜的實現（多個移動部分）: 實現 RAG 可能涉及建立向量資料庫、嵌入模型、搜索索引等。RAG 的性能取決於所有這些組件的個別性能 |
| 特定領域知識: RAG 通過從向量資料庫中提取相關結果，補充 LLMs 的特定領域知識 | 增加延遲: RAG 中的檢索步驟涉及搜索資料庫，這可能會在生成回應時引入延遲，與不依賴外部來源的模型相比。 |
| 減少幻覺和引用: RAG 通過將 LLMs 與外部、可驗證的事實結合，減少了幻覺的可能性，並且還可以引用來源 |  |
| 成本效益: RAG 是一種具有成本效益的解決方案，避免了大量模型訓練或微調的需求 |  |

## **選擇 RAG、特定領域微調和特定領域預訓練之間**

![types_domain_task.png](img/types_domain_task.png)

### **在以下情況使用領域特定的預訓練:**

- **專屬領域專注:** 當您需要一個專門在特定領域數據上訓練的模型時，預訓練是合適的，這樣可以為該領域創建一個專門的語言模型。
- **自訂模型架構:** 它允許您根據該領域的具體需求來自訂模型架構、大小、分詞器等各個方面。
- **豐富的訓練數據:** 有效的預訓練通常需要大量的領域特定訓練數據，以確保模型能夠捕捉所選領域的細微差別。

### **當使用特定領域微調時:**

- **專業化需求:** 微調適用於當你已經有一個預訓練的 LLM，並且你想要將其調整為特定任務或特定領域時。
- **任務最佳化:** 它允許你調整與任務相關的模型參數，例如架構、大小或 tokenizer，以在選定的領域中達到最佳性能。
- **時間和資源效率:** 微調相比從頭訓練模型節省了時間和計算資源，因為它利用了在預訓練階段獲得的知識。

### **使用 RAG 當:**


- **資訊新鮮度很重要:** RAG 提供來自外部來源的最新、上下文特定的資料。
- **減少幻覺至關重要:** 使用可驗證的事實和引用來支持 LLMs，來自外部知識庫。
- **成本效益是優先事項:** 避免廣泛的模型訓練或微調; 實現無需訓練。

## 閱讀/觀看這些資源 (選擇性)

1. [https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)
2. [https://www.superannotate.com/blog/llm-fine-tuning#what-is-llm-fine-tuning](https://www.superannotate.com/blog/llm-fine-tuning#what-is-llm-fine-tuning)
3. [https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrieval-Augmented Generation (RAG),sources before generating a response](https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrieval%2DAugmented%20Generation%20(RAG),sources%20before%20generating%20a%20response)。
4. [https://www.youtube.com/watch?v=cXPYtkosXG4](https://www.youtube.com/watch?v=cXPYtkosXG4)
5. [https://gradientflow.substack.com/p/best-practices-in-retrieval-augmented](https://gradientflow.substack.com/p/best-practices-in-retrieval-augmented)

## 閱讀這些論文（可選）

1. [https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf)
2. [https://arxiv.org/abs/2202.01110](https://arxiv.org/abs/2202.01110)
3. [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)

